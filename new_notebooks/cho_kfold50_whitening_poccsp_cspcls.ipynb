{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "# %reload_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from typing import Dict, List, Tuple, Any, Union, Callable\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import scipy\n",
    "from torch.utils.data import DataLoader\n",
    "from lightning.fabric.utilities.apply_func import apply_to_collection\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import torch.nn as nn\n",
    "from cspnn.csp_nn import CSP, CSPNN\n",
    "\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    cohen_kappa_score,\n",
    ")\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __init__(self, device):\n",
    "        if isinstance(device, str):\n",
    "            device = torch.device(device)\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, data, label):\n",
    "        data = apply_to_collection(\n",
    "            data,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: torch.from_numpy(a),\n",
    "        )\n",
    "        label = apply_to_collection(\n",
    "            label,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: torch.tensor(a, dtype=torch.float64),\n",
    "        )\n",
    "\n",
    "        return data, label\n",
    "\n",
    "\n",
    "class ToNumpy:\n",
    "    def __call__(self, data, label):\n",
    "        data = apply_to_collection(\n",
    "            data,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: a.cpu().detach().numpy(),\n",
    "        )\n",
    "        label = apply_to_collection(\n",
    "            label,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: a.cpu().detach().numpy(),\n",
    "        )\n",
    "\n",
    "        return data, label\n",
    "\n",
    "\n",
    "class DictToTensor:\n",
    "    def __call__(self, data: Dict[str, Tensor], label):\n",
    "        # The output shape [batch, channel, signal]\n",
    "        return (\n",
    "            torch.permute(\n",
    "                torch.vstack(list(map(lambda a: a.unsqueeze(0), data.values()))),\n",
    "                (1, 0, 2),\n",
    "            ),\n",
    "            label,\n",
    "        )\n",
    "\n",
    "\n",
    "class DictToArray:\n",
    "    def __call__(self, data, label):\n",
    "        # The output shape [batch, channel, signal]\n",
    "        return (\n",
    "            np.transpose(\n",
    "                np.vstack(\n",
    "                    list(map(lambda a: np.expand_dims(a, axis=0), data.values()))\n",
    "                ),\n",
    "                (1, 0, 2),\n",
    "            ),\n",
    "            label,\n",
    "        )\n",
    "\n",
    "\n",
    "class Windowing:\n",
    "    def __init__(self, n_segments: int = 5, sample_rate: float = 250.0):\n",
    "        self.n_segments = n_segments\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    # The Output of the signal is [batch, channels, windowed, band_filtered, signal]\n",
    "    def __call__(self, data: Tensor, label):\n",
    "        \"\"\"Takes as input a signal tensor of shape [batch, channels, band_filtered, signal]\n",
    "        and outputs a signal tensor of shape [batch, channels, windowed, band_filtered, signal]\n",
    "        \"\"\"\n",
    "        start, end = 0, data.size()[-1]\n",
    "        step = int((end - start) / self.n_segments)\n",
    "        windows = np.arange(start, end - step, step=step)\n",
    "\n",
    "        if len(windows) == 0:\n",
    "            data = data.unsqueeze(dim=2)\n",
    "            return data, label\n",
    "\n",
    "        windowed_data = torch.permute(\n",
    "            torch.stack(\n",
    "                [data[:, :, :, window : (window + step)] for window in windows], dim=0\n",
    "            ),\n",
    "            (1, 2, 0, 3, 4),\n",
    "        )\n",
    "\n",
    "        return windowed_data, label\n",
    "\n",
    "\n",
    "class Filtering:\n",
    "    def __init__(self, N: int, rs: float, Wns: List[float], bandwidth, fs: float):\n",
    "        self.N = N\n",
    "        self.rs = rs\n",
    "        self.Wns = Wns / (fs / 2)  # Normalize the signals\n",
    "        self.bandwidth = bandwidth / (fs / 2)  # Normalize the signals\n",
    "        self.fs = fs\n",
    "\n",
    "    # The Output of the signal is [batch, channels, band_filtered, signal]\n",
    "    def __call__(self, data, label):\n",
    "        filtered_data = []\n",
    "\n",
    "        for wn in self.Wns:\n",
    "            b, a = scipy.signal.cheby2(\n",
    "                N=self.N,\n",
    "                rs=self.rs,\n",
    "                Wn=[wn, wn + self.bandwidth],\n",
    "                btype=\"bandpass\",\n",
    "                fs=self.fs,\n",
    "            )\n",
    "            filtered_data.append(scipy.signal.filtfilt(b, a, data, axis=-1))\n",
    "\n",
    "        filtered_data = torch.permute(torch.Tensor(filtered_data), (1, 2, 0, 3))\n",
    "\n",
    "        return filtered_data, label\n",
    "\n",
    "\n",
    "class ExpandDim(object):\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "\n",
    "    def __call__(self, data, label):\n",
    "        return data.unsqueeze_(self.dim), label\n",
    "\n",
    "\n",
    "class LabelToDict:\n",
    "    def __call__(self, data, label):\n",
    "        return data, {\"label\": label}\n",
    "\n",
    "\n",
    "class ToNumpy:\n",
    "    def __call__(self, data, label):\n",
    "        return data.cpu().detach().numpy(), label.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self, transforms: List[Callable]) -> None:\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, data: Any, target: Any):\n",
    "        for t in self.transforms:\n",
    "            data, target = t(data, target)\n",
    "        return data, target\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\\n\".join([c.__class__.__name__ for c in self.transforms])\n",
    "\n",
    "\n",
    "# TODO: complete this part\n",
    "from scipy.signal import cheby2, filtfilt\n",
    "\n",
    "\n",
    "def cheby_bandpass_filter(signal, attenuation, lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = cheby2(order, rs=attenuation, Wn=[low, high], btype=\"band\")\n",
    "    y = filtfilt(b, a, signal, axis=-1)\n",
    "    # print(\"filtered shape \", y.shape)\n",
    "    return y\n",
    "\n",
    "\n",
    "def cheby_bandpass_one_subject(\n",
    "    X, attenuation, lowcut, highcut, fs, interval=None, verbose=True\n",
    "):\n",
    "    temp_epoch_EEG = X.copy()\n",
    "    # print(f\"data shape : {temp_epoch_EEG.shape}\")\n",
    "\n",
    "    if interval is not None:\n",
    "        startband = np.arange(lowcut, highcut, step=interval)\n",
    "\n",
    "        bands = []\n",
    "        for start in startband:\n",
    "            # This will be new key inside the EEG_filtered\n",
    "            band = \"{:02d}_{:02d}\".format(start, start + interval)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Filtering through {} Hz band\".format(band))\n",
    "            # Bandpass filtering\n",
    "            bands.append(\n",
    "                cheby_bandpass_filter(\n",
    "                    temp_epoch_EEG, attenuation, start, start + interval, fs\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return np.vstack(bands)\n",
    "\n",
    "    else:\n",
    "        # This will be new key inside the EEG_filtered\n",
    "        band = \"{:02d}_{:02d}\".format(lowcut, highcut)\n",
    "\n",
    "        return cheby_bandpass_filter(temp_epoch_EEG, attenuation, lowcut, highcut, fs)\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "class BandPass:\n",
    "    def __init__(self, attenuation, lowcut, highcut, fs, interval=None):\n",
    "        self.attenuation = attenuation\n",
    "        self.lowcut = lowcut\n",
    "        self.highcut = highcut\n",
    "        self.fs = fs\n",
    "        self.interval = interval\n",
    "\n",
    "        self.bandpass_func = partial(\n",
    "            cheby_bandpass_one_subject,\n",
    "            attenuation=self.attenuation,\n",
    "            lowcut=self.lowcut,\n",
    "            highcut=self.highcut,\n",
    "            fs=self.fs,\n",
    "            interval=self.interval,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "    # The Output of the signal is [batch, channels, band_filtered, signal]\n",
    "    def __call__(self, data, label):\n",
    "        filtered_data = data = apply_to_collection(\n",
    "            data,\n",
    "            dtype=(np.ndarray, int, float, np.int64, Tensor),\n",
    "            function=self.bandpass_func,\n",
    "        )\n",
    "\n",
    "        filtered_data = np.expand_dims(filtered_data.transpose(1, 0, 2), axis=0)\n",
    "\n",
    "        return filtered_data, label\n",
    "\n",
    "\n",
    "class Whitening:\n",
    "    def __init__(self, data_loader, whitening_method=\"PCA\"):\n",
    "        self.ds = data_loader\n",
    "        self.method = whitening_method\n",
    "\n",
    "        self.W = self._generate_whitening_transformation(self.ds, self.method)\n",
    "\n",
    "    def _generate_whitening_transformation(self, data_loader, whitening_method=\"PCA\"):\n",
    "        \"\"\"extract whitening transformation from data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_loader : torch.dataloader\n",
    "            pytorch data loader\n",
    "        whitening_method : str\n",
    "            one of following values\n",
    "            \"PCA\" for PCA whitening\n",
    "            \"ZCA for ZCA whitening\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            whitening transformation matrix\n",
    "        \"\"\"\n",
    "        # get data\n",
    "        signal = []\n",
    "        for sig, lbl in data_loader:\n",
    "            signal.append(sig)\n",
    "        signal = torch.vstack(signal)\n",
    "\n",
    "        # zero center\n",
    "        x = signal.squeeze()\n",
    "        sig = x.permute(0, 2, 1)\n",
    "        x = torch.mean(sig, axis=1)\n",
    "        x_mean = torch.mean(x, axis=0)\n",
    "\n",
    "        x = sig - x_mean\n",
    "        x_zero_centered = x.permute(0, 2, 1)\n",
    "\n",
    "        # Calculate whitening matrix\n",
    "        x_cov = self._calc_cov(x_zero_centered)\n",
    "\n",
    "        lda, V = torch.linalg.eig(x_cov)\n",
    "        lda, V = lda.real, V.real\n",
    "        if \"PCA\":\n",
    "            whitening_mat = torch.sqrt(torch.inverse(torch.diag(lda))) @ V.T\n",
    "        elif \"ZCA\":\n",
    "            whitening_mat = V @ torch.sqrt(torch.inverse(torch.diag(lda))) @ V.T\n",
    "\n",
    "        return whitening_mat\n",
    "\n",
    "    def _calc_cov(self, EEG_data):\n",
    "        cov = []\n",
    "        for i in range(EEG_data.size()[0]):\n",
    "            cov.append(\n",
    "                EEG_data[i] @ EEG_data[i].T / torch.trace(EEG_data[i] @ EEG_data[i].T)\n",
    "            )\n",
    "\n",
    "        cov = torch.mean(torch.stack(cov), 0)\n",
    "\n",
    "        return cov\n",
    "\n",
    "    def __call__(self, data: Tensor, label):\n",
    "        whitened_data = self.W @ data\n",
    "        return whitened_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
