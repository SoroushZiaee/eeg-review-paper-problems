{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf2c92b-4245-4af8-99c4-6aef21d24ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nb-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be9923b-6606-4653-b1e7-f1541bf289ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "# %reload_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30519aa-cc5c-4a2a-9e92-47d774a41d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60011c-a3e7-42c1-b150-559c77e529d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cccc8b8-caeb-43db-858f-998a2fefc7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict, List, Tuple, Any, Union, Callable\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.utilities.apply_func import apply_to_collection\n",
    "from cspnn.data.bci.bci_dataset import BCI2aDataset\n",
    "from cspnn.data.utils import eeg_electrode_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a716bcf-61fe-41cc-b946-ea462962a0ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __init__(self, device):\n",
    "        if isinstance(device, str):\n",
    "            device = torch.device(device)\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, data, label):\n",
    "        data = apply_to_collection(\n",
    "            data,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: torch.from_numpy(a),\n",
    "        )\n",
    "        label = apply_to_collection(\n",
    "            label,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: torch.tensor(a, dtype=torch.float64),\n",
    "        )\n",
    "\n",
    "        return data, label\n",
    "\n",
    "\n",
    "class ToNumpy:\n",
    "    def __call__(self, data, label):\n",
    "        data = apply_to_collection(\n",
    "            data,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: a.cpu().detach().numpy(),\n",
    "        )\n",
    "        label = apply_to_collection(\n",
    "            label,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: a.cpu().detach().numpy(),\n",
    "        )\n",
    "\n",
    "        return data, label\n",
    "\n",
    "\n",
    "class DictToTensor:\n",
    "    def __call__(self, data: Dict[str, Tensor], label):\n",
    "        # The output shape [batch, channel, signal]\n",
    "        return (\n",
    "            torch.permute(\n",
    "                torch.vstack(list(map(lambda a: a.unsqueeze(0), data.values()))),\n",
    "                (1, 0, 2),\n",
    "            ),\n",
    "            label,\n",
    "        )\n",
    "\n",
    "\n",
    "class DictToArray:\n",
    "    def __call__(self, data, label):\n",
    "        # The output shape [batch, channel, signal]\n",
    "        return (\n",
    "            np.transpose(\n",
    "                np.vstack(\n",
    "                    list(map(lambda a: np.expand_dims(a, axis=0), data.values()))\n",
    "                ),\n",
    "                (1, 0, 2),\n",
    "            ),\n",
    "            label,\n",
    "        )\n",
    "\n",
    "\n",
    "class Windowing:\n",
    "    def __init__(self, n_segments: int = 5, sample_rate: float = 250.0):\n",
    "        self.n_segments = n_segments\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    # The Output of the signal is [batch, channels, windowed, band_filtered, signal]\n",
    "    def __call__(self, data: Tensor, label):\n",
    "        \"\"\"Takes as input a signal tensor of shape [batch, channels, band_filtered, signal]\n",
    "        and outputs a signal tensor of shape [batch, channels, windowed, band_filtered, signal]\n",
    "        \"\"\"\n",
    "        start, end = 0, data.size()[-1]\n",
    "        step = int((end - start) / self.n_segments)\n",
    "        windows = np.arange(start, end - step, step=step)\n",
    "\n",
    "        if len(windows) == 0:\n",
    "            data = data.unsqueeze(dim=2)\n",
    "            return data, label\n",
    "\n",
    "        windowed_data = torch.permute(\n",
    "            torch.stack(\n",
    "                [data[:, :, :, window : (window + step)] for window in windows], dim=0\n",
    "            ),\n",
    "            (1, 2, 0, 3, 4),\n",
    "        )\n",
    "\n",
    "        return windowed_data, label\n",
    "\n",
    "\n",
    "class Filtering:\n",
    "    def __init__(self, N: int, rs: float, Wns: List[float], bandwidth, fs: float):\n",
    "        self.N = N\n",
    "        self.rs = rs\n",
    "        self.Wns = Wns / (fs / 2)  # Normalize the signals\n",
    "        self.bandwidth = bandwidth / (fs / 2)  # Normalize the signals\n",
    "        self.fs = fs\n",
    "\n",
    "    # The Output of the signal is [batch, channels, band_filtered, signal]\n",
    "    def __call__(self, data, label):\n",
    "        filtered_data = []\n",
    "\n",
    "        for wn in self.Wns:\n",
    "            b, a = scipy.signal.cheby2(\n",
    "                N=self.N,\n",
    "                rs=self.rs,\n",
    "                Wn=[wn, wn + self.bandwidth],\n",
    "                btype=\"bandpass\",\n",
    "                fs=self.fs,\n",
    "            )\n",
    "            filtered_data.append(scipy.signal.filtfilt(b, a, data, axis=-1))\n",
    "\n",
    "        filtered_data = torch.permute(torch.Tensor(filtered_data), (1, 2, 0, 3))\n",
    "\n",
    "        return filtered_data, label\n",
    "\n",
    "\n",
    "class ExpandDim(object):\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "\n",
    "    def __call__(self, data, label):\n",
    "        return data.unsqueeze_(self.dim), label\n",
    "\n",
    "\n",
    "class LabelToDict:\n",
    "    def __call__(self, data, label):\n",
    "        return data, {\"label\": label}\n",
    "\n",
    "\n",
    "class ToNumpy:\n",
    "    def __call__(self, data, label):\n",
    "        return data.cpu().detach().numpy(), label.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self, transforms: List[Callable]) -> None:\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, data: Any, target: Any):\n",
    "        for t in self.transforms:\n",
    "            data, target = t(data, target)\n",
    "        return data, target\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\\n\".join([c.__class__.__name__ for c in self.transforms])\n",
    "\n",
    "\n",
    "# TODO: complete this part\n",
    "from scipy.signal import cheby2, filtfilt\n",
    "\n",
    "\n",
    "def cheby_bandpass_filter(signal, attenuation, lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = cheby2(order, rs=attenuation, Wn=[low, high], btype=\"band\")\n",
    "    y = filtfilt(b, a, signal, axis=-1)\n",
    "    # print(\"filtered shape \", y.shape)\n",
    "    return y\n",
    "\n",
    "\n",
    "def cheby_bandpass_one_subject(\n",
    "    X, attenuation, lowcut, highcut, fs, interval=None, verbose=True\n",
    "):\n",
    "    temp_epoch_EEG = X.copy()\n",
    "    # print(f\"data shape : {temp_epoch_EEG.shape}\")\n",
    "\n",
    "    if interval is not None:\n",
    "        startband = np.arange(lowcut, highcut, step=interval)\n",
    "\n",
    "        bands = []\n",
    "        for start in startband:\n",
    "            # This will be new key inside the EEG_filtered\n",
    "            band = \"{:02d}_{:02d}\".format(start, start + interval)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Filtering through {} Hz band\".format(band))\n",
    "            # Bandpass filtering\n",
    "            bands.append(\n",
    "                cheby_bandpass_filter(\n",
    "                    temp_epoch_EEG, attenuation, start, start + interval, fs\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return np.vstack(bands)\n",
    "\n",
    "    else:\n",
    "        # This will be new key inside the EEG_filtered\n",
    "        band = \"{:02d}_{:02d}\".format(lowcut, highcut)\n",
    "\n",
    "        return cheby_bandpass_filter(temp_epoch_EEG, attenuation, lowcut, highcut, fs)\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "class BandPass:\n",
    "    def __init__(self, attenuation, lowcut, highcut, fs, interval=None):\n",
    "        self.attenuation = attenuation\n",
    "        self.lowcut = lowcut\n",
    "        self.highcut = highcut\n",
    "        self.fs = fs\n",
    "        self.interval = interval\n",
    "\n",
    "        self.bandpass_func = partial(\n",
    "            cheby_bandpass_one_subject,\n",
    "            attenuation=self.attenuation,\n",
    "            lowcut=self.lowcut,\n",
    "            highcut=self.highcut,\n",
    "            fs=self.fs,\n",
    "            interval=self.interval,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "    # The Output of the signal is [batch, channels, band_filtered, signal]\n",
    "    def __call__(self, data, label):\n",
    "        filtered_data = data = apply_to_collection(\n",
    "            data,\n",
    "            dtype=(np.ndarray, int, float, np.int64, Tensor),\n",
    "            function=self.bandpass_func,\n",
    "        )\n",
    "\n",
    "        filtered_data = np.expand_dims(filtered_data.transpose(1, 0, 2), axis=0)\n",
    "\n",
    "        return filtered_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c1ca1c-3ee5-439d-be82-523e85faf35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../test_data\"\n",
    "electrod_positions, shape = eeg_electrode_configs(\n",
    "    \"../configs/eeg_recording_standard/international_10_20_22.py\"\n",
    ")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "\n",
    "fs = 250\n",
    "low_freq = 4\n",
    "high_freq = 38\n",
    "bandwidth = 4\n",
    "overlap = 2\n",
    "\n",
    "freqs = np.arange(low_freq, high_freq - (bandwidth - overlap), overlap)\n",
    "\n",
    "lowcut = 4\n",
    "highcut = 40\n",
    "fs = 250\n",
    "attenuation = 40\n",
    "interval = 4\n",
    "\n",
    "transforms = [\n",
    "    ToTensor(device=\"cuda\"),\n",
    "    DictToTensor(),\n",
    "    # ToNumpy(),\n",
    "    # BandPass(\n",
    "    #     attenuation=attenuation,\n",
    "    #     lowcut=lowcut,\n",
    "    #     highcut=highcut,\n",
    "    #     fs=fs,\n",
    "    #     interval=interval,\n",
    "    # ),\n",
    "    # ToTensor(device=\"cpu\"),\n",
    "    # Filtering(N=4, rs=40, Wns=freqs, bandwidth=bandwidth, fs=fs),\n",
    "    ExpandDim(dim=2),\n",
    "    ExpandDim(dim=2),\n",
    "    # Windowing(n_segments=1),\n",
    "    LabelToDict(),\n",
    "]\n",
    "compose = Compose(transforms=transforms)\n",
    "\n",
    "ds = BCI2aDataset(\n",
    "    eeg_electrode_positions=electrod_positions,\n",
    "    data_path=directory,\n",
    "    transforms=compose,\n",
    "    in_mem=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e39c04-9b10-422c-a83b-b680b3bfea28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(ds)):\n",
    "    wave, label = ds[i]\n",
    "    print(wave.min(), wave.max())\n",
    "    print(wave.shape)\n",
    "    if np.isnan(wave).any() or np.isinf(wave).any():\n",
    "        print(f\"date {i} : has NAN or INF\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4beeb3f-3e2c-4a8d-93f9-f14b2d2bf155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    imgs = torch.vstack([item[0] for item in batch])\n",
    "\n",
    "    trgts = {}\n",
    "    sample_item_label = batch[0][1]\n",
    "    for label_key in sample_item_label.keys():\n",
    "        if isinstance(sample_item_label[label_key], dict):\n",
    "            trgts[label_key] = {\n",
    "                key: torch.vstack([item[1][label_key][key].squeeze() for item in batch])\n",
    "                for key in sample_item_label[label_key].keys()\n",
    "            }\n",
    "        else:\n",
    "            trgts[label_key] = torch.vstack(\n",
    "                [item[1][label_key] for item in batch]\n",
    "            ).squeeze()\n",
    "\n",
    "    return [imgs, trgts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05fd663e-d920-440d-932d-d2e225744a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset, val_dataset = ds.get_train_test_subsets()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=os.cpu_count(),\n",
    ")\n",
    "\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=os.cpu_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ac82d-6f53-45c3-87a3-af820ae9381e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d17aaf20-45a1-4345-97a8-b9c93a8b5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "from cspnn.csp_nn import CSP, CSPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "478a2bff-311f-4b26-a27c-b9b646712a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d94a4ce-32c0-4251-81b0-6fa1f1728165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    cohen_kappa_score,\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d9e7654-ea43-49e2-9c45-b36e591e7720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"modified code from:\n",
    "    https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch\"\"\"\n",
    "\n",
    "    def __init__(self, use_last=100, tolerance=50, min_delta=0):\n",
    "        self.use_last = use_last\n",
    "        self.tolerance = tolerance\n",
    "        self.min_delta = min_delta\n",
    "        self.last_100 = np.zeros((self.use_last,))\n",
    "        self.best_val_acc = np.finfo(np.float64).max\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, validation_acc):\n",
    "        self.counter += 1\n",
    "        if validation_acc > self.best_val_acc:\n",
    "            self.best_val_acc = validation_acc\n",
    "            self.last_100 = np.zeros((self.use_last,))\n",
    "        self.last_100[self.counter % self.use_last] = (\n",
    "            1 if self.best_val_acc - validation_acc > self.min_delta else 0\n",
    "        )\n",
    "        if np.sum(self.last_100) >= self.tolerance:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d077f51-096f-4342-9eb3-32f911205f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_channels: int, num_bands: int, num_features: int, num_windows: int = 1\n",
    "    ):\n",
    "        super(CSPNN, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.num_bands = num_bands\n",
    "        self.num_features = num_features\n",
    "        self.num_windows = num_windows\n",
    "\n",
    "        self.template = \"band-{}_window-{}\"\n",
    "\n",
    "        # self.conv1 = nn.ModuleList()\n",
    "        # for _ in range(self.num_bands):\n",
    "        #     self.conv1.append(\n",
    "        #         nn.Conv2d(1, self.num_filters, (self.num_channels, 1), padding=0)\n",
    "        #     )\n",
    "        self.csp = nn.ModuleDict(\n",
    "            [\n",
    "                (\n",
    "                    self.template.format(*i),\n",
    "                    nn.Conv2d(\n",
    "                        1,\n",
    "                        self.num_features,\n",
    "                        (self.num_channels, 1),\n",
    "                        padding=0,\n",
    "                        bias=False,\n",
    "                    ),\n",
    "                )\n",
    "                for i in itertools.product(\n",
    "                    range(self.num_bands),\n",
    "                    range(self.num_windows),\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(self.num_bands * self.num_features, 500)\n",
    "        self.fc = nn.Linear(500, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [batch, channel, window, band, signal] to [batch, window, band, channel, signal]\n",
    "        x = x.permute(0, 2, 3, 1, 4)\n",
    "\n",
    "        x = torch.vstack(\n",
    "            [\n",
    "                self.csp[self.template.format(*i)](\n",
    "                    x[:, i[1], i[0], :, :].unsqueeze(1)\n",
    "                ).unsqueeze(0)\n",
    "                for i in itertools.product(\n",
    "                    range(self.num_bands),\n",
    "                    range(self.num_windows),\n",
    "                )\n",
    "            ]\n",
    "        ).squeeze()  # [batch, band, filters(kernels), signal]\n",
    "\n",
    "        if len(x.size()) <= 3:\n",
    "            x = x.unsqueeze(0)\n",
    "            if self.num_bands == 1:\n",
    "                x = x.permute(1, 0, 2, 3)\n",
    "        else:\n",
    "            x = x.permute(1, 0, 2, 3)\n",
    "\n",
    "        # print(x.size())\n",
    "\n",
    "        # [batch, band, filters(kernels), signal]\n",
    "        x = torch.pow(x, 2)  # [batch, band, filters(kernels), signal] ^ 2\n",
    "        # print(x.size())\n",
    "\n",
    "        csp = torch.sum(x, dim=3)  # [batch, band, filters(kernels)]\n",
    "        # print(f\"{csp.size()=}\")\n",
    "\n",
    "        features = csp.reshape((-1, self.num_bands * self.num_features))\n",
    "        # print(f\"{features.size()=}\")\n",
    "\n",
    "        x = torch.tanh(self.fc1(features))\n",
    "        x = F.dropout(x, 0.5)\n",
    "\n",
    "        x = F.softmax(self.fc(x), dim=1)\n",
    "        if self.training:\n",
    "            return x, csp\n",
    "        return x\n",
    "\n",
    "\n",
    "net = CSPNN(num_channels=22, num_bands=1, num_features=16)\n",
    "\n",
    "# print(net.forward(Variable(torch.Tensor(np.random.rand(1, 1, 120, 64)).cuda(0))))\n",
    "cls_criterion = nn.CrossEntropyLoss()  # nn.BCELoss()\n",
    "optimizer = optim.SGD(\n",
    "    net.parameters(), lr=0.0001, momentum=0.9, nesterov=True, weight_decay=0\n",
    ")\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.0001, weight_decay=1)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "#     optimizer, max_lr=0.1, steps_per_epoch=1, epochs=200\n",
    "# )\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.1)\n",
    "early_stop = EarlyStopping(use_last=100, tolerance=50, min_delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2c4dd5f-93d5-49e0-aed4-887d52ef28c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 4]), torch.Size([10, 1, 16]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals = torch.empty((10, 22, 1, 16, 769), dtype=torch.float32).random_(1, 50)\n",
    "a, b = net(signals)\n",
    "a.size(), b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6f76e-493d-4193-b330-8ee365d02967",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CSPNNCls(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_channels: int,\n",
    "        num_features: int = None,\n",
    "        num_bands: int = None,\n",
    "        num_windows: int = 1,\n",
    "        num_labels: int = None,\n",
    "        mode: str = \"constant\",\n",
    "    ):\n",
    "        super(CSPNNCls, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.num_features = num_channels if num_features is None else num_features\n",
    "        self.num_bands = num_bands\n",
    "        self.num_windows = num_windows\n",
    "        self.num_labels = num_labels\n",
    "        self.mode = mode\n",
    "\n",
    "        self.conv1 = CSPNN(\n",
    "            num_channels=num_channels,\n",
    "            num_features=num_features,\n",
    "            num_bands=num_bands,\n",
    "            num_windows=num_windows,\n",
    "            num_labels=num_labels,\n",
    "            mode=self.mode,\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(\n",
    "            self.num_bands * self.num_windows * self.num_labels * self.num_features, 500\n",
    "        )\n",
    "        self.fc = nn.Linear(500, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        csp = self.conv1(x)\n",
    "\n",
    "        features = csp.reshape(\n",
    "            (\n",
    "                -1,\n",
    "                self.num_bands * self.num_windows * self.num_labels * self.num_features,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        x = torch.tanh(self.fc1(features))\n",
    "\n",
    "        x = F.softmax(self.fc(x), dim=1)\n",
    "        if self.training:\n",
    "            return x, csp\n",
    "        return x\n",
    "\n",
    "\n",
    "net = CSPNNCls(\n",
    "    num_channels=22,\n",
    "    num_features=22,\n",
    "    num_bands=1,\n",
    "    num_windows=1,\n",
    "    num_labels=4,\n",
    "    mode=\"csp\",\n",
    ")\n",
    "# .cuda(0)\n",
    "cls_criterion = nn.CrossEntropyLoss()  # nn.BCELoss()\n",
    "# reg_criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.00)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "#     optimizer, max_lr=0.1, steps_per_epoch=1, epochs=200\n",
    "# )\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a07ba-ee42-401a-b26c-53efb42fb326",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "signals = torch.empty((10, 22, 1, 16, 769), dtype=torch.float32).random_(1, 50)\n",
    "a, b = net(signals)\n",
    "a.size(), b.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88352a5d-2595-4daa-a411-4516c590949d",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76a8edb8-9677-47f7-8603-367429f03339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CSPNN(\n",
       "  (csp): ModuleDict(\n",
       "    (band-0_window-0): Conv2d(1, 16, kernel_size=(22, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=16, out_features=500, bias=True)\n",
       "  (fc): Linear(in_features=500, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = net.cuda()\n",
    "net = net.to(\"cuda\")\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cc495e2-621e-4554-8e93-099c2ac997ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dl, params=[\"acc\"]):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    predicted = []\n",
    "    Y = []\n",
    "\n",
    "    for batch in dl:\n",
    "        inputs, labels = batch\n",
    "        # inputs = torch.permute(\n",
    "        #     torch.vstack(list(map(lambda a: a.unsqueeze(0), inputs.values()))),\n",
    "        #     (1, 2, 3, 0),\n",
    "        # )\n",
    "        # wrap them in Variable\n",
    "        # inputs, labels = inputs.cuda(0), labels.type(torch.LongTensor).cuda(0)\n",
    "\n",
    "        pred = model(inputs.float().cuda(0))\n",
    "\n",
    "        predicted.append(pred.cpu().detach())\n",
    "        Y.append(labels[\"label\"].type(torch.LongTensor).cpu())\n",
    "\n",
    "    predicted = torch.cat(predicted, 0)\n",
    "    Y = torch.cat(Y, 0)\n",
    "\n",
    "    loss = cls_criterion(predicted, Y)\n",
    "\n",
    "    predicted = predicted.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    for param in params:\n",
    "        if param == \"acc\":\n",
    "            results.append(accuracy_score(Y, np.argmax(predicted, axis=1)))\n",
    "        if param == \"auc\":\n",
    "            results.append(roc_auc_score(Y, predicted, multi_class=\"ovr\"))\n",
    "        if param == \"kappa\":\n",
    "            results.append(cohen_kappa_score(Y, np.argmax(predicted, axis=1)))\n",
    "        if param == \"recall\":\n",
    "            results.append(\n",
    "                recall_score(Y, np.argmax(predicted, axis=1), average=\"micro\")\n",
    "            )\n",
    "        if param == \"precision\":\n",
    "            results.append(\n",
    "                precision_score(Y, np.argmax(predicted, axis=1), average=\"micro\")\n",
    "            )\n",
    "        if param == \"fmeasure\":\n",
    "            precision = precision_score(\n",
    "                Y, np.argmax(predicted, axis=1), average=\"micro\"\n",
    "            )\n",
    "            recall = recall_score(Y, np.argmax(predicted, axis=1), average=\"micro\")\n",
    "            results.append(2 * precision * recall / (precision + recall))\n",
    "\n",
    "    results.append(loss)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba450cc6-3030-44da-866a-2e2851688ffc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 28.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3963151346018285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.24112654320987653, -0.011831275720164625, 0.24112654320987653, tensor(1.3982)]\n",
      "Validation -  [0.24112654320987653, -0.011831275720164625, 0.24112654320987653, tensor(1.3982)]\n",
      "\n",
      "Epoch  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 25.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3974023159639335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.23726851851851852, -0.016975308641975273, 0.23726851851851852, tensor(1.4017)]\n",
      "Validation -  [0.2341820987654321, -0.021090534979423925, 0.23418209876543214, tensor(1.4059)]\n",
      "\n",
      "Epoch  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 28.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3962863198033086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.24382716049382716, -0.008230452674897082, 0.24382716049382716, tensor(1.4000)]\n",
      "Validation -  [0.2368827160493827, -0.017489711934156382, 0.2368827160493827, tensor(1.3997)]\n",
      "\n",
      "Epoch  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 30.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3999224974785323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2569444444444444, 0.0092592592592593, 0.2569444444444444, tensor(1.3932)]\n",
      "Validation -  [0.2496141975308642, -0.0005144032921811093, 0.2496141975308642, tensor(1.3961)]\n",
      "\n",
      "Epoch  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 25.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3958349404511627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2496141975308642, -0.0005144032921811093, 0.2496141975308642, tensor(1.3924)]\n",
      "Validation -  [0.2357253086419753, -0.019032921810699488, 0.2357253086419753, tensor(1.3985)]\n",
      "\n",
      "Epoch  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 33.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3966165133464483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.24691358024691357, -0.004115226337448652, 0.24691358024691357, tensor(1.3940)]\n",
      "Validation -  [0.25462962962962965, 0.006172839506172867, 0.25462962962962965, tensor(1.3925)]\n",
      "\n",
      "Epoch  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 26.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.394768797321084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2492283950617284, -0.0010288065843622185, 0.2492283950617284, tensor(1.3932)]\n",
      "Validation -  [0.2496141975308642, -0.0005144032921811093, 0.2496141975308642, tensor(1.3961)]\n",
      "\n",
      "Epoch  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 27.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3939804795347615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2361111111111111, -0.0185185185185186, 0.2361111111111111, tensor(1.3982)]\n",
      "Validation -  [0.2496141975308642, -0.0005144032921811093, 0.2496141975308642, tensor(1.3962)]\n",
      "\n",
      "Epoch  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 27.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.396002173423767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.23842592592592593, -0.015432098765432167, 0.23842592592592593, tensor(1.3973)]\n",
      "Validation -  [0.2662037037037037, 0.021604938271604923, 0.2662037037037037, tensor(1.3930)]\n",
      "\n",
      "Epoch  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 27.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.391854339175754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.24344135802469136, -0.008744855967078191, 0.24344135802469136, tensor(1.3962)]\n",
      "Validation -  [0.2631172839506173, 0.017489711934156382, 0.2631172839506173, tensor(1.3942)]\n",
      "\n",
      "Epoch  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 24.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3955723312166002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2492283950617284, -0.0010288065843622185, 0.2492283950617284, tensor(1.3934)]\n",
      "Validation -  [0.24537037037037038, -0.006172839506172867, 0.24537037037037038, tensor(1.3927)]\n",
      "\n",
      "Epoch  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 29.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3895527404031636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25810185185185186, 0.010802469135802517, 0.25810185185185186, tensor(1.3924)]\n",
      "Validation -  [0.2496141975308642, -0.0005144032921811093, 0.2496141975308642, tensor(1.3951)]\n",
      "\n",
      "Epoch  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 28.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3903088525489524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2503858024691358, 0.0005144032921811093, 0.2503858024691358, tensor(1.3957)]\n",
      "Validation -  [0.23765432098765432, -0.016460905349794164, 0.23765432098765432, tensor(1.3957)]\n",
      "\n",
      "Epoch  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 30.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.390341314268701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25578703703703703, 0.007716049382716084, 0.25578703703703703, tensor(1.3927)]\n",
      "Validation -  [0.26273148148148145, 0.016975308641975273, 0.26273148148148145, tensor(1.3913)]\n",
      "\n",
      "Epoch  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 34.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3889009775938812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.24845679012345678, -0.002057613168724215, 0.24845679012345678, tensor(1.3925)]\n",
      "Validation -  [0.2692901234567901, 0.025720164609053464, 0.2692901234567901, tensor(1.3878)]\n",
      "\n",
      "Epoch  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 26.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3943364708511918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2569444444444444, 0.0092592592592593, 0.2569444444444444, tensor(1.3887)]\n",
      "Validation -  [0.25655864197530864, 0.008744855967078191, 0.25655864197530864, tensor(1.3917)]\n",
      "\n",
      "Epoch  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 31.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3982030109122947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25540123456790126, 0.007201646090534974, 0.25540123456790126, tensor(1.3929)]\n",
      "Validation -  [0.2631172839506173, 0.017489711934156382, 0.2631172839506173, tensor(1.3873)]\n",
      "\n",
      "Epoch  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 26.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3900538741806407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25462962962962965, 0.006172839506172867, 0.25462962962962965, tensor(1.3926)]\n",
      "Validation -  [0.24151234567901234, -0.011316872427983515, 0.2415123456790123, tensor(1.3962)]\n",
      "\n",
      "Epoch  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 34.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3912410265133706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.24228395061728394, -0.010288065843621297, 0.24228395061728397, tensor(1.3947)]\n",
      "Validation -  [0.2515432098765432, 0.002057613168724326, 0.2515432098765432, tensor(1.3923)]\n",
      "\n",
      "Epoch  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 31.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3925491954073494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2604166666666667, 0.01388888888888884, 0.2604166666666667, tensor(1.3900)]\n",
      "Validation -  [0.24382716049382716, -0.008230452674897082, 0.24382716049382716, tensor(1.3940)]\n",
      "\n",
      "Epoch  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 28.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.392199080667378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.23919753086419754, -0.014403292181069949, 0.23919753086419754, tensor(1.3949)]\n",
      "Validation -  [0.24845679012345678, -0.002057613168724215, 0.24845679012345678, tensor(1.3938)]\n",
      "\n",
      "Epoch  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 28.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.392427126566569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2692901234567901, 0.025720164609053464, 0.2692901234567901, tensor(1.3878)]\n",
      "Validation -  [0.2596450617283951, 0.012860082304526732, 0.2596450617283951, tensor(1.3903)]\n",
      "\n",
      "Epoch  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 25.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3911133931006914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.251929012345679, 0.002572016460905324, 0.251929012345679, tensor(1.3931)]\n",
      "Validation -  [0.24498456790123457, -0.006687242798353976, 0.24498456790123457, tensor(1.3926)]\n",
      "\n",
      "Epoch  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 30.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3944296969307794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.22646604938271606, -0.03137860082304522, 0.22646604938271606, tensor(1.3971)]\n",
      "Validation -  [0.23958333333333334, -0.01388888888888884, 0.23958333333333334, tensor(1.3957)]\n",
      "\n",
      "Epoch  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 26.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.388960243743143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2569444444444444, 0.0092592592592593, 0.2569444444444444, tensor(1.3932)]\n",
      "Validation -  [0.25308641975308643, 0.004115226337448541, 0.25308641975308643, tensor(1.3907)]\n",
      "\n",
      "Epoch  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 26.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3904538802158686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.23804012345679013, -0.015946502057613277, 0.23804012345679013, tensor(1.3958)]\n",
      "Validation -  [0.25617283950617287, 0.008230452674897082, 0.25617283950617287, tensor(1.3898)]\n",
      "\n",
      "Epoch  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 26.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3914800867622281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25771604938271603, 0.010288065843621408, 0.25771604938271603, tensor(1.3903)]\n",
      "Validation -  [0.26157407407407407, 0.015432098765432056, 0.26157407407407407, tensor(1.3892)]\n",
      "\n",
      "Epoch  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 27.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3943752197571744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.26080246913580246, 0.014403292181069949, 0.26080246913580246, tensor(1.3886)]\n",
      "Validation -  [0.26774691358024694, 0.02366255144032925, 0.26774691358024694, tensor(1.3898)]\n",
      "\n",
      "Epoch  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 25.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3949560486240151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.24266975308641975, -0.00977366255144041, 0.24266975308641975, tensor(1.3934)]\n",
      "Validation -  [0.2503858024691358, 0.0005144032921811093, 0.2503858024691358, tensor(1.3918)]\n",
      "\n",
      "Epoch  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 28.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.39190164907479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2569444444444444, 0.0092592592592593, 0.2569444444444444, tensor(1.3921)]\n",
      "Validation -  [0.2496141975308642, -0.0005144032921811093, 0.2496141975308642, tensor(1.3913)]\n",
      "\n",
      "Epoch  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 26.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3905623106308926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2650462962962963, 0.020061728395061706, 0.2650462962962963, tensor(1.3894)]\n",
      "Validation -  [0.2511574074074074, 0.0015432098765432167, 0.2511574074074074, tensor(1.3943)]\n",
      "\n",
      "Epoch  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 24.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3908822094952618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2523148148148148, 0.0030864197530864335, 0.2523148148148148, tensor(1.3941)]\n",
      "Validation -  [0.25, 0.0, 0.25, tensor(1.3929)]\n",
      "\n",
      "Epoch  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 30.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3947065318072285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2523148148148148, 0.0030864197530864335, 0.2523148148148148, tensor(1.3912)]\n",
      "Validation -  [0.23958333333333334, -0.01388888888888884, 0.23958333333333334, tensor(1.3956)]\n",
      "\n",
      "Epoch  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 27.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3942301361649125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2511574074074074, 0.0015432098765432167, 0.2511574074074074, tensor(1.3964)]\n",
      "Validation -  [0.2465277777777778, -0.004629629629629539, 0.2465277777777778, tensor(1.3929)]\n",
      "\n",
      "Epoch  34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 26.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3927670893845734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2604166666666667, 0.01388888888888884, 0.2604166666666667, tensor(1.3899)]\n",
      "Validation -  [0.251929012345679, 0.002572016460905324, 0.251929012345679, tensor(1.3924)]\n",
      "\n",
      "Epoch  35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 26.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.392726970307621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25, 0.0, 0.25, tensor(1.3943)]\n",
      "Validation -  [0.2496141975308642, -0.0005144032921811093, 0.2496141975308642, tensor(1.3921)]\n",
      "\n",
      "Epoch  36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 29.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.393013389022262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.23842592592592593, -0.015432098765432167, 0.23842592592592593, tensor(1.3954)]\n",
      "Validation -  [0.24228395061728394, -0.010288065843621297, 0.24228395061728397, tensor(1.3948)]\n",
      "\n",
      "Epoch  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 28.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.394178714281247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2534722222222222, 0.00462962962962965, 0.2534722222222222, tensor(1.3951)]\n",
      "Validation -  [0.2492283950617284, -0.0010288065843622185, 0.2492283950617284, tensor(1.3929)]\n",
      "\n",
      "Epoch  38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 27.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3899668234365958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2523148148148148, 0.0030864197530864335, 0.2523148148148148, tensor(1.3893)]\n",
      "Validation -  [0.2523148148148148, 0.0030864197530864335, 0.2523148148148148, tensor(1.3931)]\n",
      "\n",
      "Epoch  39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 28.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.392115866696393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2503858024691358, 0.0005144032921811093, 0.2503858024691358, tensor(1.3934)]\n",
      "Validation -  [0.2349537037037037, -0.020061728395061706, 0.2349537037037037, tensor(1.3981)]\n",
      "\n",
      "Epoch  40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 28.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3930378563610124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.24074074074074073, -0.012345679012345734, 0.24074074074074073, tensor(1.3960)]\n",
      "Validation -  [0.2496141975308642, -0.0005144032921811093, 0.2496141975308642, tensor(1.3946)]\n",
      "\n",
      "Epoch  41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 27.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3918629899437045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.24537037037037038, -0.006172839506172867, 0.24537037037037038, tensor(1.3944)]\n",
      "Validation -  [0.26003086419753085, 0.013374485596707841, 0.26003086419753085, tensor(1.3907)]\n",
      "\n",
      "Epoch  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 28.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3942759463816514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2507716049382716, 0.0010288065843621075, 0.2507716049382716, tensor(1.3924)]\n",
      "Validation -  [0.23765432098765432, -0.016460905349794164, 0.23765432098765432, tensor(1.3955)]\n",
      "\n",
      "Epoch  43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 26.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3923801301438132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.24344135802469136, -0.008744855967078191, 0.24344135802469136, tensor(1.3927)]\n",
      "Validation -  [0.24344135802469136, -0.008744855967078191, 0.24344135802469136, tensor(1.3958)]\n",
      "\n",
      "Epoch  44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 30.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3903757024694372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.22916666666666666, -0.02777777777777768, 0.22916666666666666, tensor(1.3984)]\n",
      "Validation -  [0.26003086419753085, 0.013374485596707841, 0.26003086419753085, tensor(1.3896)]\n",
      "\n",
      "Epoch  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 26.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3914311049896995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2534722222222222, 0.00462962962962965, 0.2534722222222222, tensor(1.3912)]\n",
      "Validation -  [0.2511574074074074, 0.0015432098765432167, 0.2511574074074074, tensor(1.3913)]\n",
      "\n",
      "Epoch  46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 28.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.396138659229985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2515432098765432, 0.002057613168724326, 0.2515432098765432, tensor(1.3924)]\n",
      "Validation -  [0.2515432098765432, 0.002057613168724326, 0.2515432098765432, tensor(1.3945)]\n",
      "\n",
      "Epoch  47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 27.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3926484305181621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25385802469135804, 0.005144032921810648, 0.25385802469135804, tensor(1.3920)]\n",
      "Validation -  [0.23804012345679013, -0.015946502057613277, 0.23804012345679013, tensor(1.3941)]\n",
      "\n",
      "Epoch  48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:02, 29.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3920337329676122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2619598765432099, 0.015946502057613166, 0.2619598765432099, tensor(1.3888)]\n",
      "Validation -  [0.24189814814814814, -0.010802469135802406, 0.24189814814814814, tensor(1.3913)]\n",
      "\n",
      "Epoch  49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:03, 26.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'fmeasure', 'loss']\n",
      "Training Loss  1.3921751961295987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.24266975308641975, -0.00977366255144041, 0.24266975308641975, tensor(1.3940)]\n",
      "Validation -  [0.25925925925925924, 0.012345679012345734, 0.25925925925925924, tensor(1.3900)]\n"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"test_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"test_acc\": [],\n",
    "    \"train_kappa\": [],\n",
    "    \"test_kappa\": [],\n",
    "    \"train_fmeasure\": [],\n",
    "    \"test_fmeasure\": [],\n",
    "    \"lr\": [],\n",
    "}\n",
    "batch_size = 32\n",
    "alpha = 0.5\n",
    "\n",
    "for epoch in range(1000):  # loop over the dataset multiple times\n",
    "    print(\"\\nEpoch \", epoch)\n",
    "\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, batch in tqdm(enumerate(train_dataloader)):\n",
    "        # print(i)\n",
    "        inputs, labels = batch\n",
    "        # inputs = torch.permute(\n",
    "        #     torch.vstack(list(map(lambda a: a.unsqueeze(0), inputs.values()))),\n",
    "        #     (1, 2, 3, 0),\n",
    "        # )\n",
    "\n",
    "        # wrap them in Variable\n",
    "        # inputs, labels = inputs.cuda(0), labels.type(torch.LongTensor).cuda(0)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, csp_out = net(inputs.float().cuda(0))\n",
    "        cls_loss = cls_criterion(\n",
    "            outputs, labels[\"label\"].type(torch.LongTensor).cuda(0)\n",
    "        )\n",
    "        # reg_loss = reg_criterion(csp, labels[\"csp\"].cuda(0))\n",
    "        # loss = cls_loss + (alpha * reg_loss)\n",
    "        loss = cls_loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    history[\"lr\"].append(optimizer.param_groups[0][\"lr\"])\n",
    "    # print(optimizer.param_groups[0][\"lr\"])\n",
    "    # lr_scheduler.step()\n",
    "\n",
    "    # Validation accuracy\n",
    "    # params = [\"acc\", \"kappa\", \"auc\", \"fmeasure\", \"loss\"]\n",
    "\n",
    "    params = [\"acc\", \"kappa\", \"fmeasure\", \"loss\"]\n",
    "    print(params)\n",
    "    print(\"Training Loss \", running_loss / len(train_dataloader))\n",
    "    tr = evaluate(net, train_dataloader, params)\n",
    "    print(\"Train - \", tr)\n",
    "    ev = evaluate(net, val_dataloader, params)\n",
    "    print(\"Validation - \", ev)\n",
    "    history[\"train_loss\"].append(tr[-1])\n",
    "    history[\"train_acc\"].append(tr[0])\n",
    "    history[\"train_kappa\"].append(tr[1])\n",
    "    history[\"train_fmeasure\"].append(tr[2])\n",
    "\n",
    "    history[\"test_loss\"].append(ev[-1])\n",
    "    history[\"test_acc\"].append(ev[0])\n",
    "    history[\"test_kappa\"].append(ev[1])\n",
    "    history[\"test_fmeasure\"].append(ev[2])\n",
    "\n",
    "    if early_stop(ev[0]):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8190fb-6f62-4f3f-8377-acedc4cc27b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: history[k][-1] for k in history.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a827c-161b-4d7b-9081-b4ca819387ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmax(history[\"test_acc\"])\n",
    "{k: history[k][idx] for k in history.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504a9078-81aa-4aba-a8bf-627b4dc4b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e086b3-85de-49fc-a064-8f9e275b52d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(len(history[\"lr\"]))], history[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c99087-08b0-4edb-b68f-2bd2da7106b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "for i, title in enumerate(\n",
    "    [\n",
    "        \"train_loss\",\n",
    "        \"train_acc\",\n",
    "        \"train_kappa\",\n",
    "        \"test_loss\",\n",
    "        \"test_acc\",\n",
    "        \"test_kappa\",\n",
    "    ]\n",
    "):\n",
    "    axs[i // 3, i % 3].plot([i for i in range(len(history[title]))], history[title])\n",
    "    axs[i // 3, i % 3].set_title(title)\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel=\"epochs\", ylabel=\"\")\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
