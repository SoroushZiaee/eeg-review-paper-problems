{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf2c92b-4245-4af8-99c4-6aef21d24ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nb-black in /usr/local/lib/python3.8/dist-packages (1.0.7)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from nb-black) (8.4.0)\n",
      "Requirement already satisfied: black>='19.3' in /usr/local/lib/python3.8/dist-packages (from nb-black) (23.1.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (2.0.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (4.3.0)\n",
      "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (23.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (8.1.3)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (3.0.0)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (0.5.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (0.18.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (3.0.31)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (2.13.0)\n",
      "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (5.3.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/lib/python3/dist-packages (from ipython->nb-black) (45.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (0.1.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython->nb-black) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3->ipython->nb-black) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->nb-black) (0.2.5)\n",
      "Requirement already satisfied: asttokens in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython->nb-black) (2.0.8)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython->nb-black) (0.2.2)\n",
      "Requirement already satisfied: executing in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython->nb-black) (1.0.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from asttokens->stack-data->ipython->nb-black) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nb-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be9923b-6606-4653-b1e7-f1541bf289ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "# %reload_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c30519aa-cc5c-4a2a-9e92-47d774a41d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60011c-a3e7-42c1-b150-559c77e529d4",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cccc8b8-caeb-43db-858f-998a2fefc7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict, List, Tuple, Any, Union, Callable\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.utilities.apply_func import apply_to_collection\n",
    "from cspnn.data.bci.bci_dataset import BCI2aDataset\n",
    "from cspnn.data.utils import eeg_electrode_configs\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a716bcf-61fe-41cc-b946-ea462962a0ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __init__(self, device):\n",
    "        if isinstance(device, str):\n",
    "            device = torch.device(device)\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, data, label):\n",
    "        data = apply_to_collection(\n",
    "            data,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: torch.from_numpy(a),\n",
    "        )\n",
    "        label = apply_to_collection(\n",
    "            label,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: torch.tensor(a, dtype=torch.float64),\n",
    "        )\n",
    "\n",
    "        return data, label\n",
    "\n",
    "\n",
    "class ToNumpy:\n",
    "    def __call__(self, data, label):\n",
    "        data = apply_to_collection(\n",
    "            data,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: a.cpu().detach().numpy(),\n",
    "        )\n",
    "        label = apply_to_collection(\n",
    "            label,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: a.cpu().detach().numpy(),\n",
    "        )\n",
    "\n",
    "        return data, label\n",
    "\n",
    "\n",
    "class DictToTensor:\n",
    "    def __call__(self, data: Dict[str, Tensor], label):\n",
    "        # The output shape [batch, channel, signal]\n",
    "        return (\n",
    "            torch.permute(\n",
    "                torch.vstack(list(map(lambda a: a.unsqueeze(0), data.values()))),\n",
    "                (1, 0, 2),\n",
    "            ),\n",
    "            label,\n",
    "        )\n",
    "\n",
    "\n",
    "class DictToArray:\n",
    "    def __call__(self, data, label):\n",
    "        # The output shape [batch, channel, signal]\n",
    "        return (\n",
    "            np.transpose(\n",
    "                np.vstack(\n",
    "                    list(map(lambda a: np.expand_dims(a, axis=0), data.values()))\n",
    "                ),\n",
    "                (1, 0, 2),\n",
    "            ),\n",
    "            label,\n",
    "        )\n",
    "\n",
    "\n",
    "class Windowing:\n",
    "    def __init__(self, n_segments: int = 5, sample_rate: float = 250.0):\n",
    "        self.n_segments = n_segments\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    # The Output of the signal is [batch, channels, windowed, band_filtered, signal]\n",
    "    def __call__(self, data: Tensor, label):\n",
    "        \"\"\"Takes as input a signal tensor of shape [batch, channels, band_filtered, signal]\n",
    "        and outputs a signal tensor of shape [batch, channels, windowed, band_filtered, signal]\n",
    "        \"\"\"\n",
    "        start, end = 0, data.size()[-1]\n",
    "        step = int((end - start) / self.n_segments)\n",
    "        windows = np.arange(start, end - step, step=step)\n",
    "\n",
    "        if len(windows) == 0:\n",
    "            data = data.unsqueeze(dim=2)\n",
    "            return data, label\n",
    "\n",
    "        windowed_data = torch.permute(\n",
    "            torch.stack(\n",
    "                [data[:, :, :, window : (window + step)] for window in windows], dim=0\n",
    "            ),\n",
    "            (1, 2, 0, 3, 4),\n",
    "        )\n",
    "\n",
    "        return windowed_data, label\n",
    "\n",
    "\n",
    "class Filtering:\n",
    "    def __init__(self, N: int, rs: float, Wns: List[float], bandwidth, fs: float):\n",
    "        self.N = N\n",
    "        self.rs = rs\n",
    "        self.Wns = Wns / (fs / 2)  # Normalize the signals\n",
    "        self.bandwidth = bandwidth / (fs / 2)  # Normalize the signals\n",
    "        self.fs = fs\n",
    "\n",
    "    # The Output of the signal is [batch, channels, band_filtered, signal]\n",
    "    def __call__(self, data, label):\n",
    "        filtered_data = []\n",
    "\n",
    "        for wn in self.Wns:\n",
    "            b, a = scipy.signal.cheby2(\n",
    "                N=self.N,\n",
    "                rs=self.rs,\n",
    "                Wn=[wn, wn + self.bandwidth],\n",
    "                btype=\"bandpass\",\n",
    "                fs=self.fs,\n",
    "            )\n",
    "            filtered_data.append(scipy.signal.filtfilt(b, a, data, axis=-1))\n",
    "\n",
    "        filtered_data = torch.permute(torch.Tensor(filtered_data), (1, 2, 0, 3))\n",
    "\n",
    "        return filtered_data, label\n",
    "\n",
    "\n",
    "class ExpandDim(object):\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "\n",
    "    def __call__(self, data, label):\n",
    "        return data.unsqueeze_(self.dim), label\n",
    "\n",
    "\n",
    "class LabelToDict:\n",
    "    def __call__(self, data, label):\n",
    "        return data, {\"label\": label}\n",
    "\n",
    "\n",
    "class ToNumpy:\n",
    "    def __call__(self, data, label):\n",
    "        return data.cpu().detach().numpy(), label.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self, transforms: List[Callable]) -> None:\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, data: Any, target: Any):\n",
    "        for t in self.transforms:\n",
    "            data, target = t(data, target)\n",
    "        return data, target\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\\n\".join([c.__class__.__name__ for c in self.transforms])\n",
    "\n",
    "\n",
    "# TODO: complete this part\n",
    "from scipy.signal import cheby2, filtfilt\n",
    "\n",
    "\n",
    "def cheby_bandpass_filter(signal, attenuation, lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = cheby2(order, rs=attenuation, Wn=[low, high], btype=\"band\")\n",
    "    y = filtfilt(b, a, signal, axis=-1)\n",
    "    # print(\"filtered shape \", y.shape)\n",
    "    return y\n",
    "\n",
    "\n",
    "def cheby_bandpass_one_subject(\n",
    "    X, attenuation, lowcut, highcut, fs, interval=None, verbose=True\n",
    "):\n",
    "    temp_epoch_EEG = X.copy()\n",
    "    # print(f\"data shape : {temp_epoch_EEG.shape}\")\n",
    "\n",
    "    if interval is not None:\n",
    "        startband = np.arange(lowcut, highcut, step=interval)\n",
    "\n",
    "        bands = []\n",
    "        for start in startband:\n",
    "            # This will be new key inside the EEG_filtered\n",
    "            band = \"{:02d}_{:02d}\".format(start, start + interval)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Filtering through {} Hz band\".format(band))\n",
    "            # Bandpass filtering\n",
    "            bands.append(\n",
    "                cheby_bandpass_filter(\n",
    "                    temp_epoch_EEG, attenuation, start, start + interval, fs\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return np.vstack(bands)\n",
    "\n",
    "    else:\n",
    "        # This will be new key inside the EEG_filtered\n",
    "        band = \"{:02d}_{:02d}\".format(lowcut, highcut)\n",
    "\n",
    "        return cheby_bandpass_filter(temp_epoch_EEG, attenuation, lowcut, highcut, fs)\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "class BandPass:\n",
    "    def __init__(self, attenuation, lowcut, highcut, fs, interval=None):\n",
    "        self.attenuation = attenuation\n",
    "        self.lowcut = lowcut\n",
    "        self.highcut = highcut\n",
    "        self.fs = fs\n",
    "        self.interval = interval\n",
    "\n",
    "        self.bandpass_func = partial(\n",
    "            cheby_bandpass_one_subject,\n",
    "            attenuation=self.attenuation,\n",
    "            lowcut=self.lowcut,\n",
    "            highcut=self.highcut,\n",
    "            fs=self.fs,\n",
    "            interval=self.interval,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "    # The Output of the signal is [batch, channels, band_filtered, signal]\n",
    "    def __call__(self, data, label):\n",
    "        filtered_data = data = apply_to_collection(\n",
    "            data,\n",
    "            dtype=(np.ndarray, int, float, np.int64, Tensor),\n",
    "            function=self.bandpass_func,\n",
    "        )\n",
    "\n",
    "        filtered_data = np.expand_dims(filtered_data.transpose(1, 0, 2), axis=0)\n",
    "\n",
    "        return filtered_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c1ca1c-3ee5-439d-be82-523e85faf35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../test_data\"\n",
    "electrod_positions, shape = eeg_electrode_configs(\n",
    "    \"../configs/eeg_recording_standard/international_10_20_22.py\"\n",
    ")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "\n",
    "fs = 250\n",
    "low_freq = 4\n",
    "high_freq = 38\n",
    "bandwidth = 4\n",
    "overlap = 2\n",
    "\n",
    "freqs = np.arange(low_freq, high_freq - (bandwidth - overlap), overlap)\n",
    "\n",
    "lowcut = 4\n",
    "highcut = 40\n",
    "fs = 250\n",
    "attenuation = 40\n",
    "interval = 4\n",
    "\n",
    "transforms = [\n",
    "    ToTensor(device=\"cuda\"),\n",
    "    DictToTensor(),\n",
    "    # ToNumpy(),\n",
    "    # BandPass(\n",
    "    #     attenuation=attenuation,\n",
    "    #     lowcut=lowcut,\n",
    "    #     highcut=highcut,\n",
    "    #     fs=fs,\n",
    "    #     interval=interval,\n",
    "    # ),\n",
    "    # ToTensor(device=\"cpu\"),\n",
    "    # Filtering(N=4, rs=40, Wns=freqs, bandwidth=bandwidth, fs=fs),\n",
    "    ExpandDim(dim=2),\n",
    "    ExpandDim(dim=2),\n",
    "    # Windowing(n_segments=1),\n",
    "    LabelToDict(),\n",
    "]\n",
    "compose = Compose(transforms=transforms)\n",
    "\n",
    "ds = BCI2aDataset(\n",
    "    eeg_electrode_positions=electrod_positions,\n",
    "    data_path=directory,\n",
    "    transforms=compose,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e39c04-9b10-422c-a83b-b680b3bfea28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-22.1658, dtype=torch.float64) tensor(18.0601, dtype=torch.float64)\n",
      "torch.Size([1, 22, 1, 1, 1001])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ds)):\n",
    "    wave, label = ds[i]\n",
    "    print(wave.min(), wave.max())\n",
    "    print(wave.shape)\n",
    "    if np.isnan(wave).any() or np.isinf(wave).any():\n",
    "        print(f\"date {i} : has NAN or INF\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4beeb3f-3e2c-4a8d-93f9-f14b2d2bf155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    imgs = torch.vstack([item[0] for item in batch])\n",
    "\n",
    "    trgts = {}\n",
    "    sample_item_label = batch[0][1]\n",
    "    for label_key in sample_item_label.keys():\n",
    "        if isinstance(sample_item_label[label_key], dict):\n",
    "            trgts[label_key] = {\n",
    "                key: torch.vstack([item[1][label_key][key].squeeze() for item in batch])\n",
    "                for key in sample_item_label[label_key].keys()\n",
    "            }\n",
    "        else:\n",
    "            trgts[label_key] = torch.vstack(\n",
    "                [item[1][label_key] for item in batch]\n",
    "            ).squeeze()\n",
    "\n",
    "    return [imgs, trgts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05fd663e-d920-440d-932d-d2e225744a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset, val_dataset = ds.get_train_test_subsets()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=os.cpu_count(),\n",
    ")\n",
    "\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=os.cpu_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491a9be7-7113-4384-beb6-9565f55f012b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Investigating Whitening Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888cc158-3cd6-4fc7-a691-f804755f8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "csp_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b08bdbd8-abc4-48c3-82ec-1074ea4a8959",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd534d8701f0402c9a2b1cfef8b6a37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2592 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal = []\n",
    "label = []\n",
    "for sig, lbl in tqdm(csp_dataloader):\n",
    "    signal.append(sig)\n",
    "    label.append(lbl[\"label\"])\n",
    "signal = torch.vstack(signal)\n",
    "label = torch.stack(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a42440e1-cfa7-49ec-92f7-88db12fe9a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2592, 22, 1, 1, 1001]), torch.Size([2592]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.size(), label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15b440b8-6bd3-4805-8c67-282e69cdda44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b284aace-e3ae-43dd-adf7-29afe51222a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cov(EEG_data):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    EEG_data : EEG_data in shape T x N x S\n",
    "\n",
    "    OUTPUT:\n",
    "    avg_cov : covariance matrix of averaged over all trials\n",
    "    \"\"\"\n",
    "    cov = []\n",
    "    for i in range(EEG_data.size()[0]):\n",
    "        cov.append(\n",
    "            EEG_data[i] @ EEG_data[i].T / torch.trace(EEG_data[i] @ EEG_data[i].T)\n",
    "        )\n",
    "\n",
    "    cov = torch.mean(torch.stack(cov), 0)\n",
    "\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4e7ec38-62d3-4009-b366-1aab582f8bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2592, 1001, 22]), torch.Size([22]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = signal.squeeze()\n",
    "sig = x.permute(0, 2, 1)\n",
    "x = torch.mean(sig, axis=1)\n",
    "x_mean = torch.mean(x, axis=0)\n",
    "sig.size(), x_mean.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70e3e023-276f-41e8-95aa-f581709f8fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2592, 22, 1001])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sig - x_mean\n",
    "x_zero_centered = x.permute(0, 2, 1)\n",
    "x_zero_centered.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cdac233-db50-4e8f-be98-e05279766688",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m x_zero_centered\n\u001b[0;32m----> 2\u001b[0m x_cov \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_cov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m x_cov\u001b[38;5;241m.\u001b[39mshape\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mcalc_cov\u001b[0;34m(EEG_data)\u001b[0m\n\u001b[1;32m      9\u001b[0m cov \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EEG_data\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     11\u001b[0m     cov\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 12\u001b[0m         \u001b[43mEEG_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEEG_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mtrace(EEG_data[i] \u001b[38;5;241m@\u001b[39m EEG_data[i]\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     15\u001b[0m cov \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mstack(cov), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cov\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = x_zero_centered\n",
    "x_cov = calc_cov(x)\n",
    "x_cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef3dcd1-9362-4b66-8928-2999451d9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_cov, cmap=\"hot\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e44b43c-f0e6-478d-bced-6025fef11d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda, V = torch.linalg.eig(x_cov)\n",
    "lda, V = lda.real, V.real\n",
    "whitening_mat = V @ torch.sqrt(torch.inverse(torch.diag(lda))) @ V.T\n",
    "# print(torch.allclose(whitening_mat, torch.sqrt(torch.inverse(x_cov))))\n",
    "# whitening_mat = torch.inverse(torch.sqrt(x_cov))\n",
    "\n",
    "whitening_mat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e21ee2-940e-4a61-8d5f-c7e0687b21f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(whitening_mat, cmap=\"hot\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37139678-717e-4457-aac3-0a40179b2cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "whitened_signal = whitening_mat @ x_zero_centered\n",
    "whitened_signal.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461375fd-20b2-4cbd-810e-333202ff0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = whitened_signal\n",
    "whitened_signal_cov = calc_cov(x)\n",
    "whitened_signal_cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39dea40-0318-44e8-8ef1-1cdb4ced3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(whitened_signal_cov, cmap=\"hot\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a02d78e-80eb-47f4-af1b-63b8aed8e160",
   "metadata": {},
   "source": [
    "## Pytorch Dataset Transform Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47c474fe-34b7-47b8-b0bf-b08d9892c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Whitening:\n",
    "    def __init__(self, data_loader, whitening_method=\"PCA\"):\n",
    "        self.ds = data_loader\n",
    "        self.method = whitening_method\n",
    "\n",
    "        self.W = self._generate_whitening_transformation(self.ds, self.method)\n",
    "\n",
    "    def _generate_whitening_transformation(self, data_loader, whitening_method=\"PCA\"):\n",
    "        \"\"\"extract whitening transformation from data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_loader : torch.dataloader\n",
    "            pytorch data loader\n",
    "        whitening_method : str\n",
    "            one of following values\n",
    "            \"PCA\" for PCA whitening\n",
    "            \"ZCA for ZCA whitening\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            whitening transformation matrix\n",
    "        \"\"\"\n",
    "        # get data\n",
    "        signal = []\n",
    "        for sig, lbl in data_loader:\n",
    "            signal.append(sig)\n",
    "        signal = torch.vstack(signal)\n",
    "\n",
    "        # zero center\n",
    "        x = signal.squeeze()\n",
    "        sig = x.permute(0, 2, 1)\n",
    "        x = torch.mean(sig, axis=1)\n",
    "        x_mean = torch.mean(x, axis=0)\n",
    "\n",
    "        x = sig - x_mean\n",
    "        x_zero_centered = x.permute(0, 2, 1)\n",
    "\n",
    "        # Calculate whitening matrix\n",
    "        x_cov = self._calc_cov(x_zero_centered)\n",
    "\n",
    "        lda, V = torch.linalg.eig(x_cov)\n",
    "        lda, V = lda.real, V.real\n",
    "        if \"PCA\":\n",
    "            whitening_mat = torch.sqrt(torch.inverse(torch.diag(lda))) @ V.T\n",
    "        elif \"ZCA\":\n",
    "            whitening_mat = V @ torch.sqrt(torch.inverse(torch.diag(lda))) @ V.T\n",
    "\n",
    "        return whitening_mat\n",
    "\n",
    "    def _calc_cov(self, EEG_data):\n",
    "        cov = []\n",
    "        for i in range(EEG_data.size()[0]):\n",
    "            cov.append(\n",
    "                EEG_data[i] @ EEG_data[i].T / torch.trace(EEG_data[i] @ EEG_data[i].T)\n",
    "            )\n",
    "\n",
    "        cov = torch.mean(torch.stack(cov), 0)\n",
    "\n",
    "        return cov\n",
    "\n",
    "    def __call__(self, data: Tensor, label):\n",
    "        whitened_data = self.W @ data\n",
    "        return whitened_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5833add1-d9e9-4428-83f1-ba095efb1ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    ToTensor(device=\"cuda\"),\n",
    "    DictToTensor(),\n",
    "    ExpandDim(dim=2),\n",
    "    ExpandDim(dim=2),\n",
    "    LabelToDict(),\n",
    "]\n",
    "compose = Compose(transforms=transforms)\n",
    "\n",
    "ds = BCI2aDataset(\n",
    "    eeg_electrode_positions=electrod_positions,\n",
    "    data_path=directory,\n",
    "    transforms=compose,\n",
    "    patients=[6],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e3992fc-ec25-4929-b052-f37142b7d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = ds.get_train_test_subsets()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51edea53-25d1-48f8-8e89-12a53bd1a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    ToTensor(device=\"cuda\"),\n",
    "    DictToTensor(),\n",
    "    Whitening(train_dataloader, whitening_method=\"ZCA\"),\n",
    "    ExpandDim(dim=2),\n",
    "    ExpandDim(dim=2),\n",
    "    LabelToDict(),\n",
    "]\n",
    "compose = Compose(transforms=transforms)\n",
    "\n",
    "ds_w = BCI2aDataset(\n",
    "    eeg_electrode_positions=electrod_positions,\n",
    "    data_path=directory,\n",
    "    transforms=compose,\n",
    "    patients=[6],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "741e8378-24c6-4924-8f7c-c9abb180de8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22, 1, 1, 1001])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_w[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "317a275e-90d4-43ed-99f4-3b4f02d38e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset, _ = ds_w.get_train_test_subsets()\n",
    "\n",
    "# train_dataloader = DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=1,\n",
    "#     shuffle=False,\n",
    "#     collate_fn=collate_fn,\n",
    "#     num_workers=1,\n",
    "# )\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset, val_dataset = ds_w.get_train_test_subsets()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=os.cpu_count(),\n",
    ")\n",
    "\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=os.cpu_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5267478d-8717-4785-adce-16d2c577db34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e819154e1264de3bd4633055a674bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([288, 22, 1, 1, 1001])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal = []\n",
    "for sig, lbl in tqdm(train_dataloader):\n",
    "    signal.append(sig)\n",
    "signal = torch.vstack(signal)\n",
    "signal.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8e983d9-b1c4-4b23-857d-22cc16a4a96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 22])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitened_signal_cov = calc_cov(signal.squeeze())\n",
    "whitened_signal_cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5507a7b3-fc3c-4247-b78a-3d19885b5cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(whitened_signal_cov, cmap=\"hot\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a9f9b-25c4-405d-b8b7-fb2296eaf81f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33e0509b-507d-4e4e-8a98-747f9db77aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from cspnn.csp_nn import CSP, CSPNN\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    cohen_kappa_score,\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f5d6d0e-ccb8-42ad-84b6-8b31f2d7f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dl, params=[\"acc\"]):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    predicted = []\n",
    "    Y = []\n",
    "\n",
    "    for batch in dl:\n",
    "        inputs, labels = batch\n",
    "        # inputs = torch.permute(\n",
    "        #     torch.vstack(list(map(lambda a: a.unsqueeze(0), inputs.values()))),\n",
    "        #     (1, 2, 3, 0),\n",
    "        # )\n",
    "        # wrap them in Variable\n",
    "        # inputs, labels = inputs.cuda(0), labels.type(torch.LongTensor).cuda(0)\n",
    "\n",
    "        pred = model(inputs.float().cuda(0))\n",
    "\n",
    "        predicted.append(pred.cpu().detach())\n",
    "        Y.append(labels[\"label\"].type(torch.LongTensor).cpu())\n",
    "\n",
    "    predicted = torch.cat(predicted, 0)\n",
    "    Y = torch.cat(Y, 0)\n",
    "\n",
    "    loss = cls_criterion(predicted, Y)\n",
    "\n",
    "    predicted = predicted.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    for param in params:\n",
    "        if param == \"acc\":\n",
    "            results.append(accuracy_score(Y, np.argmax(predicted, axis=1)))\n",
    "        if param == \"auc\":\n",
    "            results.append(roc_auc_score(Y, predicted, multi_class=\"ovr\"))\n",
    "        if param == \"kappa\":\n",
    "            results.append(cohen_kappa_score(Y, np.argmax(predicted, axis=1)))\n",
    "        if param == \"recall\":\n",
    "            results.append(\n",
    "                recall_score(Y, np.argmax(predicted, axis=1), average=\"micro\")\n",
    "            )\n",
    "        if param == \"precision\":\n",
    "            results.append(\n",
    "                precision_score(Y, np.argmax(predicted, axis=1), average=\"micro\")\n",
    "            )\n",
    "        if param == \"fmeasure\":\n",
    "            precision = precision_score(\n",
    "                Y, np.argmax(predicted, axis=1), average=\"micro\"\n",
    "            )\n",
    "            recall = recall_score(Y, np.argmax(predicted, axis=1), average=\"micro\")\n",
    "            results.append(2 * precision * recall / (precision + recall))\n",
    "\n",
    "    results.append(loss)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7113c186-d7f3-482e-a282-feb6be39a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPNNCls(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_channels: int,\n",
    "        num_features: int = None,\n",
    "        num_bands: int = None,\n",
    "        num_windows: int = 1,\n",
    "        num_labels: int = None,\n",
    "        mode: str = \"constant\",\n",
    "    ):\n",
    "        super(CSPNNCls, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.num_features = num_channels if num_features is None else num_features\n",
    "        self.num_bands = num_bands\n",
    "        self.num_windows = num_windows\n",
    "        self.num_labels = num_labels\n",
    "        self.mode = mode\n",
    "\n",
    "        self.conv1 = CSPNN(\n",
    "            num_channels=num_channels,\n",
    "            num_features=num_features,\n",
    "            num_bands=num_bands,\n",
    "            num_windows=num_windows,\n",
    "            num_labels=num_labels,\n",
    "            mode=self.mode,\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(\n",
    "            self.num_bands * self.num_windows * self.num_labels * self.num_features, 500\n",
    "        )\n",
    "        self.fc = nn.Linear(500, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        csp = self.conv1(x)\n",
    "\n",
    "        features = csp.reshape(\n",
    "            (\n",
    "                -1,\n",
    "                self.num_bands * self.num_windows * self.num_labels * self.num_features,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        x = torch.tanh(self.fc1(features))\n",
    "\n",
    "        x = F.softmax(self.fc(x), dim=1)\n",
    "        if self.training:\n",
    "            return x, csp\n",
    "        return x\n",
    "\n",
    "\n",
    "net = CSPNNCls(\n",
    "    num_channels=22, num_features=22, num_bands=1, num_windows=1, num_labels=4\n",
    ")\n",
    "# .cuda(0)\n",
    "cls_criterion = nn.CrossEntropyLoss()  # nn.BCELoss()\n",
    "# reg_criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.00)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "#     optimizer, max_lr=0.1, steps_per_epoch=1, epochs=200\n",
    "# )\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df449bbc-f041-4f5c-bc1d-93b60e530576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 4]), torch.Size([10, 4, 22]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals = torch.empty((10, 22, 1, 16, 769), dtype=torch.float32).random_(1, 50)\n",
    "a, b = net(signals)\n",
    "a.size(), b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7238974f-9aba-4ca2-8408-008842a950ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ade78-7f8f-4d47-a9d3-1ffe24cb7e96",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.410045067469279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25, 0.0, 0.6545138888888888, 0.25, tensor(1.3957)]\n",
      "Validation -  [0.25, 0.0, 0.5653131430041153, 0.25, tensor(1.3974)]\n",
      "\n",
      "Epoch  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.4026345014572144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25, 0.0, 0.7029963991769548, 0.25, tensor(1.3953)]\n",
      "Validation -  [0.25, 0.0, 0.5963702417695473, 0.25, tensor(1.3980)]\n",
      "\n",
      "Epoch  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3997159136666193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.3333333333333333, 0.11111111111111116, 0.7193769290123457, 0.3333333333333333, tensor(1.3897)]\n",
      "Validation -  [0.2777777777777778, 0.03703703703703709, 0.6094714506172839, 0.2777777777777778, tensor(1.3923)]\n",
      "\n",
      "Epoch  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3961848550372653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2986111111111111, 0.06481481481481477, 0.7304848251028807, 0.2986111111111111, tensor(1.3865)]\n",
      "Validation -  [0.2847222222222222, 0.04629629629629628, 0.6189396862139918, 0.2847222222222222, tensor(1.3900)]\n",
      "\n",
      "Epoch  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3931303421656291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.3541666666666667, 0.13888888888888884, 0.742332175925926, 0.3541666666666667, tensor(1.3814)]\n",
      "Validation -  [0.3090277777777778, 0.07870370370370372, 0.6244212962962963, 0.3090277777777778, tensor(1.3859)]\n",
      "\n",
      "Epoch  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3937437136967976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25, 0.0, 0.7628118569958848, 0.25, tensor(1.3785)]\n",
      "Validation -  [0.25, 0.0, 0.6403034979423868, 0.25, tensor(1.3831)]\n",
      "\n",
      "Epoch  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3897584544287787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25, 0.0, 0.7708494084362141, 0.25, tensor(1.3851)]\n",
      "Validation -  [0.25, 0.0, 0.6551729681069958, 0.25, tensor(1.3928)]\n",
      "\n",
      "Epoch  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3798806269963582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.3194444444444444, 0.09259259259259256, 0.7779385288065843, 0.3194444444444444, tensor(1.3709)]\n",
      "Validation -  [0.2777777777777778, 0.03703703703703709, 0.6576163837448559, 0.2777777777777778, tensor(1.3787)]\n",
      "\n",
      "Epoch  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3729170428382025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.46875, 0.29166666666666663, 0.7784047067901235, 0.46875, tensor(1.3638)]\n",
      "Validation -  [0.3645833333333333, 0.1527777777777778, 0.6597061471193416, 0.36458333333333326, tensor(1.3746)]\n",
      "\n",
      "Epoch  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3629436890284221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2569444444444444, 0.0092592592592593, 0.7681809413580247, 0.2569444444444444, tensor(1.3599)]\n",
      "Validation -  [0.2569444444444444, 0.0092592592592593, 0.6552533436213992, 0.2569444444444444, tensor(1.3720)]\n",
      "\n",
      "Epoch  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3670838276545207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.3715277777777778, 0.1620370370370371, 0.7781153549382717, 0.3715277777777778, tensor(1.3528)]\n",
      "Validation -  [0.3020833333333333, 0.06944444444444442, 0.6640303497942388, 0.3020833333333333, tensor(1.3694)]\n",
      "\n",
      "Epoch  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3829026222229004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2604166666666667, 0.01388888888888884, 0.7594200102880657, 0.2604166666666667, tensor(1.3672)]\n",
      "Validation -  [0.2986111111111111, 0.06481481481481477, 0.6491769547325102, 0.2986111111111111, tensor(1.3794)]\n",
      "\n",
      "Epoch  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3946561680899725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.3715277777777778, 0.1620370370370371, 0.7433288323045268, 0.3715277777777778, tensor(1.3851)]\n",
      "Validation -  [0.3333333333333333, 0.11111111111111116, 0.6422968106995885, 0.3333333333333333, tensor(1.3997)]\n",
      "\n",
      "Epoch  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.4164042207929823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.3402777777777778, 0.12037037037037035, 0.7255336934156379, 0.3402777777777778, tensor(1.3861)]\n",
      "Validation -  [0.3020833333333333, 0.06944444444444442, 0.6427790637860082, 0.3020833333333333, tensor(1.3997)]\n",
      "\n",
      "Epoch  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.4039338032404582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25, 0.0, 0.7529417438271605, 0.25, tensor(1.4198)]\n",
      "Validation -  [0.25, 0.0, 0.63403420781893, 0.25, tensor(1.4353)]\n",
      "\n",
      "Epoch  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.4021201531092327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25, 0.0, 0.7028838734567902, 0.25, tensor(1.4058)]\n",
      "Validation -  [0.25, 0.0, 0.6403356481481481, 0.25, tensor(1.4116)]\n",
      "\n",
      "Epoch  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3744179275300767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25, 0.0, 0.7614454732510288, 0.25, tensor(1.4162)]\n",
      "Validation -  [0.25, 0.0, 0.6788676697530865, 0.25, tensor(1.4324)]\n",
      "\n",
      "Epoch  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.4174475140041776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.3576388888888889, 0.1435185185185185, 0.7534400720164609, 0.3576388888888889, tensor(1.3461)]\n",
      "Validation -  [0.2951388888888889, 0.06018518518518523, 0.6725180041152263, 0.2951388888888889, tensor(1.3697)]\n",
      "\n",
      "Epoch  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3476369910769992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4305555555555556, 0.2407407407407407, 0.7503375771604939, 0.4305555555555556, tensor(1.3309)]\n",
      "Validation -  [0.4097222222222222, 0.2129629629629629, 0.665943287037037, 0.4097222222222222, tensor(1.3545)]\n",
      "\n",
      "Epoch  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.331986837916904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4756944444444444, 0.30092592592592593, 0.7596450617283951, 0.4756944444444444, tensor(1.3188)]\n",
      "Validation -  [0.3368055555555556, 0.1157407407407407, 0.6655092592592593, 0.3368055555555556, tensor(1.3527)]\n",
      "\n",
      "Epoch  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3329929775661893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.3923611111111111, 0.18981481481481477, 0.7606738683127573, 0.3923611111111111, tensor(1.3188)]\n",
      "Validation -  [0.3229166666666667, 0.09722222222222221, 0.6514435442386831, 0.3229166666666667, tensor(1.3536)]\n",
      "\n",
      "Epoch  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3375204139285617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4548611111111111, 0.27314814814814814, 0.753954475308642, 0.4548611111111111, tensor(1.3114)]\n",
      "Validation -  [0.3680555555555556, 0.15740740740740744, 0.6623906893004116, 0.36805555555555564, tensor(1.3429)]\n",
      "\n",
      "Epoch  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3070135513941448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.375, 0.16666666666666663, 0.7573784722222223, 0.375, tensor(1.3213)]\n",
      "Validation -  [0.34375, 0.125, 0.6484696502057613, 0.34375, tensor(1.3552)]\n",
      "\n",
      "Epoch  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3217400974697537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.375, 0.16666666666666663, 0.7595646862139918, 0.375, tensor(1.3187)]\n",
      "Validation -  [0.3402777777777778, 0.12037037037037035, 0.6561213991769548, 0.3402777777777778, tensor(1.3533)]\n",
      "\n",
      "Epoch  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.310386406050788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4548611111111111, 0.27314814814814814, 0.7735982510288066, 0.4548611111111111, tensor(1.2869)]\n",
      "Validation -  [0.3402777777777778, 0.12037037037037035, 0.6588702417695472, 0.3402777777777778, tensor(1.3471)]\n",
      "\n",
      "Epoch  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.2995767858293321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4722222222222222, 0.2962962962962963, 0.7798353909465021, 0.4722222222222222, tensor(1.2754)]\n",
      "Validation -  [0.3784722222222222, 0.17129629629629628, 0.6599311985596708, 0.3784722222222222, tensor(1.3352)]\n",
      "\n",
      "Epoch  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.275296343697442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.5486111111111112, 0.39814814814814814, 0.7835165895061729, 0.5486111111111112, tensor(1.2635)]\n",
      "Validation -  [0.40625, 0.20833333333333337, 0.6693994341563786, 0.40625, tensor(1.3273)]\n",
      "\n",
      "Epoch  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.2702196439107258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4131944444444444, 0.21759259259259256, 0.7861207561728396, 0.4131944444444444, tensor(1.2717)]\n",
      "Validation -  [0.3611111111111111, 0.14814814814814814, 0.6681134259259259, 0.3611111111111111, tensor(1.3260)]\n",
      "\n",
      "Epoch  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.2595148351457384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4548611111111111, 0.27314814814814814, 0.79296875, 0.4548611111111111, tensor(1.2671)]\n",
      "Validation -  [0.3506944444444444, 0.1342592592592593, 0.6644322273662552, 0.3506944444444444, tensor(1.3342)]\n",
      "\n",
      "Epoch  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.279289682706197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4270833333333333, 0.23611111111111116, 0.7798032407407407, 0.4270833333333333, tensor(1.2861)]\n",
      "Validation -  [0.3680555555555556, 0.15740740740740744, 0.6774530606995885, 0.36805555555555564, tensor(1.3359)]\n",
      "\n",
      "Epoch  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.256410837173462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4201388888888889, 0.22685185185185186, 0.7931134259259258, 0.4201388888888889, tensor(1.2715)]\n",
      "Validation -  [0.3298611111111111, 0.10648148148148151, 0.6633230452674898, 0.3298611111111111, tensor(1.3356)]\n",
      "\n",
      "Epoch  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.2740878793928359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4895833333333333, 0.3194444444444444, 0.8052662037037037, 0.4895833333333333, tensor(1.2804)]\n",
      "Validation -  [0.375, 0.16666666666666663, 0.6677276234567902, 0.375, tensor(1.3516)]\n",
      "\n",
      "Epoch  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.2708492808871799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4756944444444444, 0.30092592592592593, 0.8045428240740742, 0.4756944444444444, tensor(1.2597)]\n",
      "Validation -  [0.3368055555555556, 0.1157407407407407, 0.6722608024691357, 0.3368055555555556, tensor(1.3512)]\n",
      "\n",
      "Epoch  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.2458511193593342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4791666666666667, 0.3055555555555556, 0.8232542438271605, 0.4791666666666667, tensor(1.2379)]\n",
      "Validation -  [0.3229166666666667, 0.09722222222222221, 0.6800572273662551, 0.3229166666666667, tensor(1.3373)]\n",
      "\n",
      "Epoch  34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.2817096180386014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.3993055555555556, 0.19907407407407407, 0.7948495370370371, 0.3993055555555556, tensor(1.3058)]\n",
      "Validation -  [0.3611111111111111, 0.14814814814814814, 0.6673739711934157, 0.3611111111111111, tensor(1.3556)]\n",
      "\n",
      "Epoch  35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.2873369190427992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.53125, 0.375, 0.8155542695473251, 0.53125, tensor(1.2701)]\n",
      "Validation -  [0.3819444444444444, 0.17592592592592593, 0.6788676697530864, 0.3819444444444445, tensor(1.3324)]\n",
      "\n",
      "Epoch  36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.2763502067989774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4375, 0.25, 0.8238490226337448, 0.4375, tensor(1.2755)]\n",
      "Validation -  [0.3333333333333333, 0.11111111111111116, 0.6753954475308642, 0.3333333333333333, tensor(1.3505)]\n",
      "\n",
      "Epoch  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.299472795592414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.5138888888888888, 0.35185185185185186, 0.8269675925925926, 0.5138888888888888, tensor(1.2629)]\n",
      "Validation -  [0.3888888888888889, 0.18518518518518523, 0.6803787294238683, 0.3888888888888889, tensor(1.3381)]\n",
      "\n",
      "Epoch  38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.305971172120836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.40625, 0.20833333333333337, 0.8238329475308642, 0.40625, tensor(1.3066)]\n",
      "Validation -  [0.3576388888888889, 0.1435185185185185, 0.686181841563786, 0.3576388888888889, tensor(1.3636)]\n",
      "\n",
      "Epoch  39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.2953785128063626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.3958333333333333, 0.19444444444444442, 0.8273533950617283, 0.3958333333333333, tensor(1.2888)]\n",
      "Validation -  [0.3333333333333333, 0.11111111111111116, 0.6835294495884774, 0.3333333333333333, tensor(1.3560)]\n",
      "\n",
      "Epoch  40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.300259404712253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"test_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"test_acc\": [],\n",
    "    \"lr\": [],\n",
    "    \"train_kappa\": [],\n",
    "    \"test_kappa\": [],\n",
    "}\n",
    "batch_size = 32\n",
    "alpha = 0.5\n",
    "\n",
    "for epoch in range(1000):  # loop over the dataset multiple times\n",
    "    print(\"\\nEpoch \", epoch)\n",
    "\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, batch in tqdm(enumerate(train_dataloader)):\n",
    "        \n",
    "        # print(i)\n",
    "        inputs, labels = batch\n",
    "        # inputs = torch.permute(\n",
    "        #     torch.vstack(list(map(lambda a: a.unsqueeze(0), inputs.values()))),\n",
    "        #     (1, 2, 3, 0),\n",
    "        # )\n",
    "\n",
    "        # wrap them in Variable\n",
    "        # inputs, labels = inputs.cuda(0), labels.type(torch.LongTensor).cuda(0)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, csp_out = net(inputs.float().cuda(0))\n",
    "        cls_loss = cls_criterion(\n",
    "            outputs, labels[\"label\"].type(torch.LongTensor).cuda(0)\n",
    "        )\n",
    "        # reg_loss = reg_criterion(csp, labels[\"csp\"].cuda(0))\n",
    "        # loss = cls_loss + (alpha * reg_loss)\n",
    "        loss = cls_loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    history[\"lr\"].append(optimizer.param_groups[0][\"lr\"])\n",
    "    # print(optimizer.param_groups[0][\"lr\"])\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Validation accuracy\n",
    "    params = [\"acc\", \"kappa\", \"auc\", \"fmeasure\", \"loss\"]\n",
    "    print(params)\n",
    "    print(\"Training Loss \", running_loss / len(train_dataloader))\n",
    "    tr = evaluate(net, train_dataloader, params)\n",
    "    print(\"Train - \", tr)\n",
    "    ev = evaluate(net, val_dataloader, params)\n",
    "    print(\"Validation - \", ev)\n",
    "    history[\"train_loss\"].append(tr[-1])\n",
    "    history[\"train_acc\"].append(tr[0])\n",
    "    history[\"train_kappa\"].append(tr[1])\n",
    "\n",
    "    history[\"test_loss\"].append(ev[-1])\n",
    "    history[\"test_acc\"].append(ev[0])\n",
    "    history[\"test_kappa\"].append(ev[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57260759-62f1-420e-a30b-3f1cdea1ed3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': tensor(0.9321),\n",
       " 'test_loss': tensor(1.2221),\n",
       " 'train_acc': 0.8229166666666666,\n",
       " 'test_acc': 0.5208333333333334,\n",
       " 'lr': 0.001,\n",
       " 'train_kappa': 0.7638888888888888,\n",
       " 'test_kappa': 0.36111111111111116}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argmax(history[\"test_acc\"])\n",
    "{k: history[k][idx] for k in history.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e248047-7ef3-403c-abca-f7a62b76e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984f176-0004-49ce-b610-66f7397e0f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(len(history[\"lr\"]))], history[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14c4d2-bef1-49ba-8767-4760014b4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "for i, title in enumerate(\n",
    "    [\n",
    "        \"train_loss\",\n",
    "        \"train_acc\",\n",
    "        \"train_kappa\",\n",
    "        \"test_loss\",\n",
    "        \"test_acc\",\n",
    "        \"test_kappa\",\n",
    "    ]\n",
    "):\n",
    "    axs[i // 3, i % 3].plot([i for i in range(len(history[title]))], history[title])\n",
    "    axs[i // 3, i % 3].set_title(title)\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel=\"epochs\", ylabel=\"\")\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "# for ax in axs.flat:\n",
    "#     ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a858f1-f659-41ad-9e5d-128e4a29306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "for i, title in enumerate(\n",
    "    [\n",
    "        \"train_loss\",\n",
    "        \"train_acc\",\n",
    "        \"train_kappa\",\n",
    "        \"test_loss\",\n",
    "        \"test_acc\",\n",
    "        \"test_kappa\",\n",
    "    ]\n",
    "):\n",
    "    axs[i // 3, i % 3].plot([i for i in range(len(history[title]))], history[title])\n",
    "    axs[i // 3, i % 3].set_title(title)\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel=\"epochs\", ylabel=\"\")\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "# for ax in axs.flat:\n",
    "#     ax.label_outer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
