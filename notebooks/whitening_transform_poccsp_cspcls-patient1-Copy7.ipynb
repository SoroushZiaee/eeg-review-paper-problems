{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf2c92b-4245-4af8-99c4-6aef21d24ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nb-black in /usr/local/lib/python3.8/dist-packages (1.0.7)\n",
      "Requirement already satisfied: black>='19.3' in /usr/local/lib/python3.8/dist-packages (from nb-black) (23.1.0)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from nb-black) (8.4.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (8.1.3)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (2.0.1)\n",
      "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (23.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (4.3.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (4.8.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (2.13.0)\n",
      "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (5.3.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (3.0.31)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (0.1.6)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/lib/python3/dist-packages (from ipython->nb-black) (45.2.0)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (0.5.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython->nb-black) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3->ipython->nb-black) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->nb-black) (0.2.5)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython->nb-black) (0.2.2)\n",
      "Requirement already satisfied: executing in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython->nb-black) (1.0.0)\n",
      "Requirement already satisfied: asttokens in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython->nb-black) (2.0.8)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from asttokens->stack-data->ipython->nb-black) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nb-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be9923b-6606-4653-b1e7-f1541bf289ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "# %reload_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c30519aa-cc5c-4a2a-9e92-47d774a41d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60011c-a3e7-42c1-b150-559c77e529d4",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cccc8b8-caeb-43db-858f-998a2fefc7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict, List, Tuple, Any, Union, Callable\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.utilities.apply_func import apply_to_collection\n",
    "from cspnn.data.bci.bci_dataset import BCI2aDataset\n",
    "from cspnn.data.utils import eeg_electrode_configs\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a716bcf-61fe-41cc-b946-ea462962a0ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __init__(self, device):\n",
    "        if isinstance(device, str):\n",
    "            device = torch.device(device)\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, data, label):\n",
    "        data = apply_to_collection(\n",
    "            data,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: torch.from_numpy(a),\n",
    "        )\n",
    "        label = apply_to_collection(\n",
    "            label,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: torch.tensor(a, dtype=torch.float64),\n",
    "        )\n",
    "\n",
    "        return data, label\n",
    "\n",
    "\n",
    "class ToNumpy:\n",
    "    def __call__(self, data, label):\n",
    "        data = apply_to_collection(\n",
    "            data,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: a.cpu().detach().numpy(),\n",
    "        )\n",
    "        label = apply_to_collection(\n",
    "            label,\n",
    "            dtype=(np.ndarray, int, float, np.int64),\n",
    "            function=lambda a: a.cpu().detach().numpy(),\n",
    "        )\n",
    "\n",
    "        return data, label\n",
    "\n",
    "\n",
    "class DictToTensor:\n",
    "    def __call__(self, data: Dict[str, Tensor], label):\n",
    "        # The output shape [batch, channel, signal]\n",
    "        return (\n",
    "            torch.permute(\n",
    "                torch.vstack(list(map(lambda a: a.unsqueeze(0), data.values()))),\n",
    "                (1, 0, 2),\n",
    "            ),\n",
    "            label,\n",
    "        )\n",
    "\n",
    "\n",
    "class DictToArray:\n",
    "    def __call__(self, data, label):\n",
    "        # The output shape [batch, channel, signal]\n",
    "        return (\n",
    "            np.transpose(\n",
    "                np.vstack(\n",
    "                    list(map(lambda a: np.expand_dims(a, axis=0), data.values()))\n",
    "                ),\n",
    "                (1, 0, 2),\n",
    "            ),\n",
    "            label,\n",
    "        )\n",
    "\n",
    "\n",
    "class Windowing:\n",
    "    def __init__(self, n_segments: int = 5, sample_rate: float = 250.0):\n",
    "        self.n_segments = n_segments\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    # The Output of the signal is [batch, channels, windowed, band_filtered, signal]\n",
    "    def __call__(self, data: Tensor, label):\n",
    "        \"\"\"Takes as input a signal tensor of shape [batch, channels, band_filtered, signal]\n",
    "        and outputs a signal tensor of shape [batch, channels, windowed, band_filtered, signal]\n",
    "        \"\"\"\n",
    "        start, end = 0, data.size()[-1]\n",
    "        step = int((end - start) / self.n_segments)\n",
    "        windows = np.arange(start, end - step, step=step)\n",
    "\n",
    "        if len(windows) == 0:\n",
    "            data = data.unsqueeze(dim=2)\n",
    "            return data, label\n",
    "\n",
    "        windowed_data = torch.permute(\n",
    "            torch.stack(\n",
    "                [data[:, :, :, window : (window + step)] for window in windows], dim=0\n",
    "            ),\n",
    "            (1, 2, 0, 3, 4),\n",
    "        )\n",
    "\n",
    "        return windowed_data, label\n",
    "\n",
    "\n",
    "class Filtering:\n",
    "    def __init__(self, N: int, rs: float, Wns: List[float], bandwidth, fs: float):\n",
    "        self.N = N\n",
    "        self.rs = rs\n",
    "        self.Wns = Wns / (fs / 2)  # Normalize the signals\n",
    "        self.bandwidth = bandwidth / (fs / 2)  # Normalize the signals\n",
    "        self.fs = fs\n",
    "\n",
    "    # The Output of the signal is [batch, channels, band_filtered, signal]\n",
    "    def __call__(self, data, label):\n",
    "        filtered_data = []\n",
    "\n",
    "        for wn in self.Wns:\n",
    "            b, a = scipy.signal.cheby2(\n",
    "                N=self.N,\n",
    "                rs=self.rs,\n",
    "                Wn=[wn, wn + self.bandwidth],\n",
    "                btype=\"bandpass\",\n",
    "                fs=self.fs,\n",
    "            )\n",
    "            filtered_data.append(scipy.signal.filtfilt(b, a, data, axis=-1))\n",
    "\n",
    "        filtered_data = torch.permute(torch.Tensor(filtered_data), (1, 2, 0, 3))\n",
    "\n",
    "        return filtered_data, label\n",
    "\n",
    "\n",
    "class ExpandDim(object):\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "\n",
    "    def __call__(self, data, label):\n",
    "        return data.unsqueeze_(self.dim), label\n",
    "\n",
    "\n",
    "class LabelToDict:\n",
    "    def __call__(self, data, label):\n",
    "        return data, {\"label\": label}\n",
    "\n",
    "\n",
    "class ToNumpy:\n",
    "    def __call__(self, data, label):\n",
    "        return data.cpu().detach().numpy(), label.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self, transforms: List[Callable]) -> None:\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, data: Any, target: Any):\n",
    "        for t in self.transforms:\n",
    "            data, target = t(data, target)\n",
    "        return data, target\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\\n\".join([c.__class__.__name__ for c in self.transforms])\n",
    "\n",
    "\n",
    "# TODO: complete this part\n",
    "from scipy.signal import cheby2, filtfilt\n",
    "\n",
    "\n",
    "def cheby_bandpass_filter(signal, attenuation, lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = cheby2(order, rs=attenuation, Wn=[low, high], btype=\"band\")\n",
    "    y = filtfilt(b, a, signal, axis=-1)\n",
    "    # print(\"filtered shape \", y.shape)\n",
    "    return y\n",
    "\n",
    "\n",
    "def cheby_bandpass_one_subject(\n",
    "    X, attenuation, lowcut, highcut, fs, interval=None, verbose=True\n",
    "):\n",
    "    temp_epoch_EEG = X.copy()\n",
    "    # print(f\"data shape : {temp_epoch_EEG.shape}\")\n",
    "\n",
    "    if interval is not None:\n",
    "        startband = np.arange(lowcut, highcut, step=interval)\n",
    "\n",
    "        bands = []\n",
    "        for start in startband:\n",
    "            # This will be new key inside the EEG_filtered\n",
    "            band = \"{:02d}_{:02d}\".format(start, start + interval)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Filtering through {} Hz band\".format(band))\n",
    "            # Bandpass filtering\n",
    "            bands.append(\n",
    "                cheby_bandpass_filter(\n",
    "                    temp_epoch_EEG, attenuation, start, start + interval, fs\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return np.vstack(bands)\n",
    "\n",
    "    else:\n",
    "        # This will be new key inside the EEG_filtered\n",
    "        band = \"{:02d}_{:02d}\".format(lowcut, highcut)\n",
    "\n",
    "        return cheby_bandpass_filter(temp_epoch_EEG, attenuation, lowcut, highcut, fs)\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "class BandPass:\n",
    "    def __init__(self, attenuation, lowcut, highcut, fs, interval=None):\n",
    "        self.attenuation = attenuation\n",
    "        self.lowcut = lowcut\n",
    "        self.highcut = highcut\n",
    "        self.fs = fs\n",
    "        self.interval = interval\n",
    "\n",
    "        self.bandpass_func = partial(\n",
    "            cheby_bandpass_one_subject,\n",
    "            attenuation=self.attenuation,\n",
    "            lowcut=self.lowcut,\n",
    "            highcut=self.highcut,\n",
    "            fs=self.fs,\n",
    "            interval=self.interval,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "    # The Output of the signal is [batch, channels, band_filtered, signal]\n",
    "    def __call__(self, data, label):\n",
    "        filtered_data = data = apply_to_collection(\n",
    "            data,\n",
    "            dtype=(np.ndarray, int, float, np.int64, Tensor),\n",
    "            function=self.bandpass_func,\n",
    "        )\n",
    "\n",
    "        filtered_data = np.expand_dims(filtered_data.transpose(1, 0, 2), axis=0)\n",
    "\n",
    "        return filtered_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c1ca1c-3ee5-439d-be82-523e85faf35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../test_data\"\n",
    "electrod_positions, shape = eeg_electrode_configs(\n",
    "    \"../configs/eeg_recording_standard/international_10_20_22.py\"\n",
    ")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "\n",
    "fs = 250\n",
    "low_freq = 4\n",
    "high_freq = 38\n",
    "bandwidth = 4\n",
    "overlap = 2\n",
    "\n",
    "freqs = np.arange(low_freq, high_freq - (bandwidth - overlap), overlap)\n",
    "\n",
    "lowcut = 4\n",
    "highcut = 40\n",
    "fs = 250\n",
    "attenuation = 40\n",
    "interval = 4\n",
    "\n",
    "transforms = [\n",
    "    ToTensor(device=\"cuda\"),\n",
    "    DictToTensor(),\n",
    "    # ToNumpy(),\n",
    "    # BandPass(\n",
    "    #     attenuation=attenuation,\n",
    "    #     lowcut=lowcut,\n",
    "    #     highcut=highcut,\n",
    "    #     fs=fs,\n",
    "    #     interval=interval,\n",
    "    # ),\n",
    "    # ToTensor(device=\"cpu\"),\n",
    "    # Filtering(N=4, rs=40, Wns=freqs, bandwidth=bandwidth, fs=fs),\n",
    "    ExpandDim(dim=2),\n",
    "    ExpandDim(dim=2),\n",
    "    # Windowing(n_segments=1),\n",
    "    LabelToDict(),\n",
    "]\n",
    "compose = Compose(transforms=transforms)\n",
    "\n",
    "ds = BCI2aDataset(\n",
    "    eeg_electrode_positions=electrod_positions,\n",
    "    data_path=directory,\n",
    "    transforms=compose,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e39c04-9b10-422c-a83b-b680b3bfea28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-22.1658, dtype=torch.float64) tensor(18.0601, dtype=torch.float64)\n",
      "torch.Size([1, 22, 1, 1, 1001])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ds)):\n",
    "    wave, label = ds[i]\n",
    "    print(wave.min(), wave.max())\n",
    "    print(wave.shape)\n",
    "    if np.isnan(wave).any() or np.isinf(wave).any():\n",
    "        print(f\"date {i} : has NAN or INF\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4beeb3f-3e2c-4a8d-93f9-f14b2d2bf155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    imgs = torch.vstack([item[0] for item in batch])\n",
    "\n",
    "    trgts = {}\n",
    "    sample_item_label = batch[0][1]\n",
    "    for label_key in sample_item_label.keys():\n",
    "        if isinstance(sample_item_label[label_key], dict):\n",
    "            trgts[label_key] = {\n",
    "                key: torch.vstack([item[1][label_key][key].squeeze() for item in batch])\n",
    "                for key in sample_item_label[label_key].keys()\n",
    "            }\n",
    "        else:\n",
    "            trgts[label_key] = torch.vstack(\n",
    "                [item[1][label_key] for item in batch]\n",
    "            ).squeeze()\n",
    "\n",
    "    return [imgs, trgts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05fd663e-d920-440d-932d-d2e225744a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset, val_dataset = ds.get_train_test_subsets()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=os.cpu_count(),\n",
    ")\n",
    "\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=os.cpu_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491a9be7-7113-4384-beb6-9565f55f012b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Investigating Whitening Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888cc158-3cd6-4fc7-a691-f804755f8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "csp_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b08bdbd8-abc4-48c3-82ec-1074ea4a8959",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4219919226b42ef91ded76181b30bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2592 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal = []\n",
    "label = []\n",
    "for sig, lbl in tqdm(csp_dataloader):\n",
    "    signal.append(sig)\n",
    "    label.append(lbl[\"label\"])\n",
    "signal = torch.vstack(signal)\n",
    "label = torch.stack(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a42440e1-cfa7-49ec-92f7-88db12fe9a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2592, 22, 1, 1, 1001]), torch.Size([2592]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.size(), label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15b440b8-6bd3-4805-8c67-282e69cdda44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b284aace-e3ae-43dd-adf7-29afe51222a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cov(EEG_data):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    EEG_data : EEG_data in shape T x N x S\n",
    "\n",
    "    OUTPUT:\n",
    "    avg_cov : covariance matrix of averaged over all trials\n",
    "    \"\"\"\n",
    "    cov = []\n",
    "    for i in range(EEG_data.size()[0]):\n",
    "        cov.append(\n",
    "            EEG_data[i] @ EEG_data[i].T / torch.trace(EEG_data[i] @ EEG_data[i].T)\n",
    "        )\n",
    "\n",
    "    cov = torch.mean(torch.stack(cov), 0)\n",
    "\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4e7ec38-62d3-4009-b366-1aab582f8bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2592, 1001, 22]), torch.Size([22]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = signal.squeeze()\n",
    "sig = x.permute(0, 2, 1)\n",
    "x = torch.mean(sig, axis=1)\n",
    "x_mean = torch.mean(x, axis=0)\n",
    "sig.size(), x_mean.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70e3e023-276f-41e8-95aa-f581709f8fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2592, 22, 1001])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sig - x_mean\n",
    "x_zero_centered = x.permute(0, 2, 1)\n",
    "x_zero_centered.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cdac233-db50-4e8f-be98-e05279766688",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m x_zero_centered\n\u001b[0;32m----> 2\u001b[0m x_cov \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_cov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m x_cov\u001b[38;5;241m.\u001b[39mshape\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mcalc_cov\u001b[0;34m(EEG_data)\u001b[0m\n\u001b[1;32m      9\u001b[0m cov \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EEG_data\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     11\u001b[0m     cov\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 12\u001b[0m         \u001b[43mEEG_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEEG_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mtrace(EEG_data[i] \u001b[38;5;241m@\u001b[39m EEG_data[i]\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     15\u001b[0m cov \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mstack(cov), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cov\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = x_zero_centered\n",
    "x_cov = calc_cov(x)\n",
    "x_cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef3dcd1-9362-4b66-8928-2999451d9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_cov, cmap=\"hot\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e44b43c-f0e6-478d-bced-6025fef11d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda, V = torch.linalg.eig(x_cov)\n",
    "lda, V = lda.real, V.real\n",
    "whitening_mat = V @ torch.sqrt(torch.inverse(torch.diag(lda))) @ V.T\n",
    "# print(torch.allclose(whitening_mat, torch.sqrt(torch.inverse(x_cov))))\n",
    "# whitening_mat = torch.inverse(torch.sqrt(x_cov))\n",
    "\n",
    "whitening_mat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e21ee2-940e-4a61-8d5f-c7e0687b21f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(whitening_mat, cmap=\"hot\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37139678-717e-4457-aac3-0a40179b2cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "whitened_signal = whitening_mat @ x_zero_centered\n",
    "whitened_signal.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461375fd-20b2-4cbd-810e-333202ff0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = whitened_signal\n",
    "whitened_signal_cov = calc_cov(x)\n",
    "whitened_signal_cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39dea40-0318-44e8-8ef1-1cdb4ced3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(whitened_signal_cov, cmap=\"hot\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a02d78e-80eb-47f4-af1b-63b8aed8e160",
   "metadata": {},
   "source": [
    "## Pytorch Dataset Transform Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47c474fe-34b7-47b8-b0bf-b08d9892c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Whitening:\n",
    "    def __init__(self, data_loader, whitening_method=\"PCA\"):\n",
    "        self.ds = data_loader\n",
    "        self.method = whitening_method\n",
    "\n",
    "        self.W = self._generate_whitening_transformation(self.ds, self.method)\n",
    "\n",
    "    def _generate_whitening_transformation(self, data_loader, whitening_method=\"PCA\"):\n",
    "        \"\"\"extract whitening transformation from data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_loader : torch.dataloader\n",
    "            pytorch data loader\n",
    "        whitening_method : str\n",
    "            one of following values\n",
    "            \"PCA\" for PCA whitening\n",
    "            \"ZCA for ZCA whitening\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            whitening transformation matrix\n",
    "        \"\"\"\n",
    "        # get data\n",
    "        signal = []\n",
    "        for sig, lbl in data_loader:\n",
    "            signal.append(sig)\n",
    "        signal = torch.vstack(signal)\n",
    "\n",
    "        # zero center\n",
    "        x = signal.squeeze()\n",
    "        sig = x.permute(0, 2, 1)\n",
    "        x = torch.mean(sig, axis=1)\n",
    "        x_mean = torch.mean(x, axis=0)\n",
    "\n",
    "        x = sig - x_mean\n",
    "        x_zero_centered = x.permute(0, 2, 1)\n",
    "\n",
    "        # Calculate whitening matrix\n",
    "        x_cov = self._calc_cov(x_zero_centered)\n",
    "\n",
    "        lda, V = torch.linalg.eig(x_cov)\n",
    "        lda, V = lda.real, V.real\n",
    "        if \"PCA\":\n",
    "            whitening_mat = torch.sqrt(torch.inverse(torch.diag(lda))) @ V.T\n",
    "        elif \"ZCA\":\n",
    "            whitening_mat = V @ torch.sqrt(torch.inverse(torch.diag(lda))) @ V.T\n",
    "\n",
    "        return whitening_mat\n",
    "\n",
    "    def _calc_cov(self, EEG_data):\n",
    "        cov = []\n",
    "        for i in range(EEG_data.size()[0]):\n",
    "            cov.append(\n",
    "                EEG_data[i] @ EEG_data[i].T / torch.trace(EEG_data[i] @ EEG_data[i].T)\n",
    "            )\n",
    "\n",
    "        cov = torch.mean(torch.stack(cov), 0)\n",
    "\n",
    "        return cov\n",
    "\n",
    "    def __call__(self, data: Tensor, label):\n",
    "        whitened_data = self.W @ data\n",
    "        return whitened_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5833add1-d9e9-4428-83f1-ba095efb1ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    ToTensor(device=\"cuda\"),\n",
    "    DictToTensor(),\n",
    "    ExpandDim(dim=2),\n",
    "    ExpandDim(dim=2),\n",
    "    LabelToDict(),\n",
    "]\n",
    "compose = Compose(transforms=transforms)\n",
    "\n",
    "ds = BCI2aDataset(\n",
    "    eeg_electrode_positions=electrod_positions,\n",
    "    data_path=directory,\n",
    "    transforms=compose,\n",
    "    patients=[8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e3992fc-ec25-4929-b052-f37142b7d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = ds.get_train_test_subsets()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51edea53-25d1-48f8-8e89-12a53bd1a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    ToTensor(device=\"cuda\"),\n",
    "    DictToTensor(),\n",
    "    Whitening(train_dataloader, whitening_method=\"ZCA\"),\n",
    "    ExpandDim(dim=2),\n",
    "    ExpandDim(dim=2),\n",
    "    LabelToDict(),\n",
    "]\n",
    "compose = Compose(transforms=transforms)\n",
    "\n",
    "ds_w = BCI2aDataset(\n",
    "    eeg_electrode_positions=electrod_positions,\n",
    "    data_path=directory,\n",
    "    transforms=compose,\n",
    "    patients=[8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "741e8378-24c6-4924-8f7c-c9abb180de8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22, 1, 1, 1001])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_w[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "317a275e-90d4-43ed-99f4-3b4f02d38e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset, _ = ds_w.get_train_test_subsets()\n",
    "\n",
    "# train_dataloader = DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=1,\n",
    "#     shuffle=False,\n",
    "#     collate_fn=collate_fn,\n",
    "#     num_workers=1,\n",
    "# )\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset, val_dataset = ds_w.get_train_test_subsets()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=os.cpu_count(),\n",
    ")\n",
    "\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=os.cpu_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5267478d-8717-4785-adce-16d2c577db34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c827cc130c8548ca871aea6e6906ef7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([288, 22, 1, 1, 1001])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal = []\n",
    "for sig, lbl in tqdm(train_dataloader):\n",
    "    signal.append(sig)\n",
    "signal = torch.vstack(signal)\n",
    "signal.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8e983d9-b1c4-4b23-857d-22cc16a4a96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 22])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitened_signal_cov = calc_cov(signal.squeeze())\n",
    "whitened_signal_cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5507a7b3-fc3c-4247-b78a-3d19885b5cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(whitened_signal_cov, cmap=\"hot\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a9f9b-25c4-405d-b8b7-fb2296eaf81f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33e0509b-507d-4e4e-8a98-747f9db77aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from cspnn.csp_nn import CSP, CSPNN\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    cohen_kappa_score,\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f5d6d0e-ccb8-42ad-84b6-8b31f2d7f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dl, params=[\"acc\"]):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    predicted = []\n",
    "    Y = []\n",
    "\n",
    "    for batch in dl:\n",
    "        inputs, labels = batch\n",
    "        # inputs = torch.permute(\n",
    "        #     torch.vstack(list(map(lambda a: a.unsqueeze(0), inputs.values()))),\n",
    "        #     (1, 2, 3, 0),\n",
    "        # )\n",
    "        # wrap them in Variable\n",
    "        # inputs, labels = inputs.cuda(0), labels.type(torch.LongTensor).cuda(0)\n",
    "\n",
    "        pred = model(inputs.float().cuda(0))\n",
    "\n",
    "        predicted.append(pred.cpu().detach())\n",
    "        Y.append(labels[\"label\"].type(torch.LongTensor).cpu())\n",
    "\n",
    "    predicted = torch.cat(predicted, 0)\n",
    "    Y = torch.cat(Y, 0)\n",
    "\n",
    "    loss = cls_criterion(predicted, Y)\n",
    "\n",
    "    predicted = predicted.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    for param in params:\n",
    "        if param == \"acc\":\n",
    "            results.append(accuracy_score(Y, np.argmax(predicted, axis=1)))\n",
    "        if param == \"auc\":\n",
    "            results.append(roc_auc_score(Y, predicted, multi_class=\"ovr\"))\n",
    "        if param == \"kappa\":\n",
    "            results.append(cohen_kappa_score(Y, np.argmax(predicted, axis=1)))\n",
    "        if param == \"recall\":\n",
    "            results.append(\n",
    "                recall_score(Y, np.argmax(predicted, axis=1), average=\"micro\")\n",
    "            )\n",
    "        if param == \"precision\":\n",
    "            results.append(\n",
    "                precision_score(Y, np.argmax(predicted, axis=1), average=\"micro\")\n",
    "            )\n",
    "        if param == \"fmeasure\":\n",
    "            precision = precision_score(\n",
    "                Y, np.argmax(predicted, axis=1), average=\"micro\"\n",
    "            )\n",
    "            recall = recall_score(Y, np.argmax(predicted, axis=1), average=\"micro\")\n",
    "            results.append(2 * precision * recall / (precision + recall))\n",
    "\n",
    "    results.append(loss)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7113c186-d7f3-482e-a282-feb6be39a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPNNCls(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_channels: int,\n",
    "        num_features: int = None,\n",
    "        num_bands: int = None,\n",
    "        num_windows: int = 1,\n",
    "        num_labels: int = None,\n",
    "        mode: str = \"constant\",\n",
    "    ):\n",
    "        super(CSPNNCls, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.num_features = num_channels if num_features is None else num_features\n",
    "        self.num_bands = num_bands\n",
    "        self.num_windows = num_windows\n",
    "        self.num_labels = num_labels\n",
    "        self.mode = mode\n",
    "\n",
    "        self.conv1 = CSPNN(\n",
    "            num_channels=num_channels,\n",
    "            num_features=num_features,\n",
    "            num_bands=num_bands,\n",
    "            num_windows=num_windows,\n",
    "            num_labels=num_labels,\n",
    "            mode=self.mode,\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(\n",
    "            self.num_bands * self.num_windows * self.num_labels * self.num_features, 500\n",
    "        )\n",
    "        self.fc = nn.Linear(500, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        csp = self.conv1(x)\n",
    "\n",
    "        features = csp.reshape(\n",
    "            (\n",
    "                -1,\n",
    "                self.num_bands * self.num_windows * self.num_labels * self.num_features,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        x = torch.tanh(self.fc1(features))\n",
    "\n",
    "        x = F.softmax(self.fc(x), dim=1)\n",
    "        if self.training:\n",
    "            return x, csp\n",
    "        return x\n",
    "\n",
    "\n",
    "net = CSPNNCls(\n",
    "    num_channels=22, num_features=22, num_bands=1, num_windows=1, num_labels=4\n",
    ")\n",
    "# .cuda(0)\n",
    "cls_criterion = nn.CrossEntropyLoss()  # nn.BCELoss()\n",
    "# reg_criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.00)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "#     optimizer, max_lr=0.1, steps_per_epoch=1, epochs=200\n",
    "# )\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df449bbc-f041-4f5c-bc1d-93b60e530576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 4]), torch.Size([10, 4, 22]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals = torch.empty((10, 22, 1, 16, 769), dtype=torch.float32).random_(1, 50)\n",
    "a, b = net(signals)\n",
    "a.size(), b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7238974f-9aba-4ca2-8408-008842a950ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ade78-7f8f-4d47-a9d3-1ffe24cb7e96",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:03,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.407771150271098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25, 0.0, 0.8266943158436214, 0.25, tensor(1.3952)]\n",
      "Validation -  [0.25, 0.0, 0.74731545781893, 0.25, tensor(1.3997)]\n",
      "\n",
      "Epoch  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.4030527008904352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25, 0.0, 0.8854809670781894, 0.25, tensor(1.3846)]\n",
      "Validation -  [0.25, 0.0, 0.8005079732510288, 0.25, tensor(1.3882)]\n",
      "\n",
      "Epoch  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3861383597056072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.25, 0.0, 0.8780381944444444, 0.25, tensor(1.3843)]\n",
      "Validation -  [0.25, 0.0, 0.7938368055555555, 0.25, tensor(1.3863)]\n",
      "\n",
      "Epoch  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.382351901796129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4618055555555556, 0.28240740740740744, 0.8998521090534979, 0.4618055555555556, tensor(1.3634)]\n",
      "Validation -  [0.3472222222222222, 0.12962962962962965, 0.8372235082304528, 0.3472222222222222, tensor(1.3715)]\n",
      "\n",
      "Epoch  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3638801574707031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.2638888888888889, 0.01851851851851849, 0.8716403034979424, 0.2638888888888889, tensor(1.3516)]\n",
      "Validation -  [0.3472222222222222, 0.12962962962962965, 0.8072595164609053, 0.3472222222222222, tensor(1.3570)]\n",
      "\n",
      "Epoch  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.3314631912443373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4965277777777778, 0.3287037037037037, 0.9171810699588478, 0.4965277777777778, tensor(1.3120)]\n",
      "Validation -  [0.375, 0.16666666666666663, 0.8681841563786009, 0.375, tensor(1.3369)]\n",
      "\n",
      "Epoch  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.301339930958218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.4583333333333333, 0.2777777777777778, 0.8845003858024691, 0.4583333333333333, tensor(1.2868)]\n",
      "Validation -  [0.5833333333333334, 0.4444444444444444, 0.8346997170781894, 0.5833333333333334, tensor(1.3048)]\n",
      "\n",
      "Epoch  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.2830317550235324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.3576388888888889, 0.1435185185185185, 0.8434445730452675, 0.3576388888888889, tensor(1.2981)]\n",
      "Validation -  [0.4583333333333333, 0.2777777777777778, 0.8009098508230453, 0.4583333333333333, tensor(1.3003)]\n",
      "\n",
      "Epoch  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.269066294034322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.5451388888888888, 0.3935185185185185, 0.9077610596707819, 0.5451388888888888, tensor(1.2216)]\n",
      "Validation -  [0.6319444444444444, 0.5092592592592593, 0.8673643261316872, 0.6319444444444444, tensor(1.2517)]\n",
      "\n",
      "Epoch  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.2185340060128107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.6215277777777778, 0.49537037037037035, 0.9388503086419753, 0.6215277777777778, tensor(1.1777)]\n",
      "Validation -  [0.5347222222222222, 0.37962962962962965, 0.8736336162551441, 0.5347222222222222, tensor(1.2414)]\n",
      "\n",
      "Epoch  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.1650896337297227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.6770833333333334, 0.5694444444444444, 0.9400318287037037, 0.6770833333333334, tensor(1.1464)]\n",
      "Validation -  [0.6180555555555556, 0.4907407407407407, 0.8927147633744856, 0.6180555555555556, tensor(1.2064)]\n",
      "\n",
      "Epoch  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'kappa', 'auc', 'fmeasure', 'loss']\n",
      "Training Loss  1.1367282337612576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -  [0.7083333333333334, 0.6111111111111112, 0.9546039094650206, 0.7083333333333334, tensor(1.1129)]\n"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"test_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"test_acc\": [],\n",
    "    \"lr\": [],\n",
    "    \"train_kappa\": [],\n",
    "    \"test_kappa\": [],\n",
    "}\n",
    "batch_size = 32\n",
    "alpha = 0.5\n",
    "\n",
    "for epoch in range(1000):  # loop over the dataset multiple times\n",
    "    print(\"\\nEpoch \", epoch)\n",
    "\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, batch in tqdm(enumerate(train_dataloader)):\n",
    "        \n",
    "        # print(i)\n",
    "        inputs, labels = batch\n",
    "        # inputs = torch.permute(\n",
    "        #     torch.vstack(list(map(lambda a: a.unsqueeze(0), inputs.values()))),\n",
    "        #     (1, 2, 3, 0),\n",
    "        # )\n",
    "\n",
    "        # wrap them in Variable\n",
    "        # inputs, labels = inputs.cuda(0), labels.type(torch.LongTensor).cuda(0)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, csp_out = net(inputs.float().cuda(0))\n",
    "        cls_loss = cls_criterion(\n",
    "            outputs, labels[\"label\"].type(torch.LongTensor).cuda(0)\n",
    "        )\n",
    "        # reg_loss = reg_criterion(csp, labels[\"csp\"].cuda(0))\n",
    "        # loss = cls_loss + (alpha * reg_loss)\n",
    "        loss = cls_loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    history[\"lr\"].append(optimizer.param_groups[0][\"lr\"])\n",
    "    # print(optimizer.param_groups[0][\"lr\"])\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Validation accuracy\n",
    "    params = [\"acc\", \"kappa\", \"auc\", \"fmeasure\", \"loss\"]\n",
    "    print(params)\n",
    "    print(\"Training Loss \", running_loss / len(train_dataloader))\n",
    "    tr = evaluate(net, train_dataloader, params)\n",
    "    print(\"Train - \", tr)\n",
    "    ev = evaluate(net, val_dataloader, params)\n",
    "    print(\"Validation - \", ev)\n",
    "    history[\"train_loss\"].append(tr[-1])\n",
    "    history[\"train_acc\"].append(tr[0])\n",
    "    history[\"train_kappa\"].append(tr[1])\n",
    "\n",
    "    history[\"test_loss\"].append(ev[-1])\n",
    "    history[\"test_acc\"].append(ev[0])\n",
    "    history[\"test_kappa\"].append(ev[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57260759-62f1-420e-a30b-3f1cdea1ed3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': tensor(0.7641),\n",
       " 'test_loss': tensor(0.9646),\n",
       " 'train_acc': 0.9895833333333334,\n",
       " 'test_acc': 0.78125,\n",
       " 'lr': 0.001,\n",
       " 'train_kappa': 0.9861111111111112,\n",
       " 'test_kappa': 0.7083333333333333}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argmax(history[\"test_acc\"])\n",
    "{k: history[k][idx] for k in history.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e248047-7ef3-403c-abca-f7a62b76e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984f176-0004-49ce-b610-66f7397e0f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(len(history[\"lr\"]))], history[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14c4d2-bef1-49ba-8767-4760014b4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "for i, title in enumerate(\n",
    "    [\n",
    "        \"train_loss\",\n",
    "        \"train_acc\",\n",
    "        \"train_kappa\",\n",
    "        \"test_loss\",\n",
    "        \"test_acc\",\n",
    "        \"test_kappa\",\n",
    "    ]\n",
    "):\n",
    "    axs[i // 3, i % 3].plot([i for i in range(len(history[title]))], history[title])\n",
    "    axs[i // 3, i % 3].set_title(title)\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel=\"epochs\", ylabel=\"\")\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "# for ax in axs.flat:\n",
    "#     ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a858f1-f659-41ad-9e5d-128e4a29306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "for i, title in enumerate(\n",
    "    [\n",
    "        \"train_loss\",\n",
    "        \"train_acc\",\n",
    "        \"train_kappa\",\n",
    "        \"test_loss\",\n",
    "        \"test_acc\",\n",
    "        \"test_kappa\",\n",
    "    ]\n",
    "):\n",
    "    axs[i // 3, i % 3].plot([i for i in range(len(history[title]))], history[title])\n",
    "    axs[i // 3, i % 3].set_title(title)\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel=\"epochs\", ylabel=\"\")\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "# for ax in axs.flat:\n",
    "#     ax.label_outer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
